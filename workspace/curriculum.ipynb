{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# カリキュラム"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データサイエンス初級\n",
    "---\n",
    "データに基づいた分析手法を実行できる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数学復習\n",
    "---\n",
    "- $1+4+9+16+25+36$を$\\sum _{}$を用いて表せる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### マーケット・バスケット分析\n",
    "---\n",
    "- 条件付き確率の意味を説明できる\n",
    " - ベン図を用いて視覚的に\n",
    "- ベイズの定理を説明できる\n",
    "- 条件Xと事象Yの関係性をリフト値を用いて評価できる\n",
    "- アプリオリアルゴリズムのアソシエーション分析において、統計ツールのパラメータをチューニングして出⼒件数を調整できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 概論\n",
    "---\n",
    "[なぜデータサイエンスのゼネラリストになるべきではないのか](http://ainow.ai/2018/12/18/156854/)\n",
    "- 目的やゴールの設定がないままデータを分析しても、意味合いが出ないことを理解している\n",
    " - 以降の各節冒頭で必ずデータから仮説を考えるようにする\n",
    "- 課題や仮説を言語化することの重要性を理解している\n",
    "- 一般的な収益方程式に加え、自らが担当する業務の主要な変数(KPI)を理解している\n",
    "- 現場に出向いてヒアリングするなど、一次情報に接することの重要性を理解している\n",
    "- 結果、改善の度合いをモニタリングする重要性を理解している\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ把握"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データ要約について\n",
    "---\n",
    "- ニュース記事などで統計情報に接したときに、数字やグラフの持つメッセージを理解できる\n",
    "- データ解析部門以外の方に、データの意味を伝えるサインとしての可視化ができる\n",
    "- 可視化の目的の広がりの概略について説明できる（単に現場の作業⽀援する場合から、ビッグデータ中の要素間の関連性をダイナミックに表示する場合など）\n",
    "- 単独のグラフに対して、集計ミスなどがないかチェックできる\n",
    "- データの可視化における基本的な視点を挙げることができる（特異点、相違性、傾向性、関連性を⾒出すなど）\n",
    "- 分析、図表から直接的な意味合いを抽出できる（バラツキ、有意性、分布傾向、特異性、関連性、変曲点、関連度の⾼低など）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数値要約"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1変数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 代表値\n",
    "---\n",
    "- 平均（相加平均）、中央値、最頻値の算出方法の違いを説明できる\n",
    "- 名義尺度、順序尺度、間隔尺度、比例尺度の違いを説明できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 分散・標準偏差\n",
    "---\n",
    "- 母集団データ$（3,4,5,5,7,8）$の分散と標準偏差を電卓を用いて計算できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2変数\n",
    "---\n",
    "- 一般的な相関係数（ピアソン）の分母と分子を説明できる\n",
    "- 変数が量的、質的どちらの場合の関係の強さも算出できる\n",
    "- 適切な軸設定でクロス集計表を作成し、属性間のデータの偏りを把握できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 数値要約の注意点\n",
    "---\n",
    "- データが⽣み出された背景を考え、鵜呑みにはしないことの重要性を理解している\n",
    "- 何のために集計しているか、どのような知⾒を得たいのか、目的に即して集計できる\n",
    "- 加⼯済データに分析上の不具合がないか検証できる\n",
    "- データから事実を正しく浮き彫りにするために、集計の切り口や⽐較対象の設定が重要であることを理解している\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### グラフ描画"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1変数\n",
    "---\n",
    "- 適切なデータ区間設定でヒストグラムを作成し、データのバラつき方を把握できる\n",
    " - pd.cutで離散化→棒グラフでヒストグラムを擬似的に作成する演習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2変数\n",
    "---\n",
    "- 量的変数の散布図を描き、2変数の関係性を把握することができる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 層化\n",
    "---\n",
    "- 積み上げ縦棒グラフでの属性の選択など、適切な層化（⽐較軸）の候補を出せる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### グラフ表示の注意点\n",
    "---\n",
    "- 散布図などの軸だしにおいて、縦軸・横軸の候補を適切に洗い出せる\n",
    "- 不必要な誇張をしないための軸表現の基礎を理解できている（コラムチャートのY軸の基準点は「0」からを原則とし軸を切らないなど） \n",
    " - 実際に不適切なグラフを描画して比較する演習\n",
    "- 強調表現がもたらす効果と、明らかに不適切な強調表現を理解している（計量データに対しては位置やサイズ表現が色表現よりも効果的など）\n",
    " - グラフの引数を変えて、強調表現を比較する演習\n",
    "- 1〜3次元の⽐較において目的（⽐較、構成、分布、変化など）に応じた図表化ができる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データ把握まとめ\n",
    "---\n",
    "- データの性質を理解するために、データを可視化し眺めて考えることの重要性を理解している\n",
    " - [Anscombeの例](https://ja.wikipedia.org/wiki/%E3%82%A2%E3%83%B3%E3%82%B9%E3%82%B3%E3%83%A0%E3%81%AE%E4%BE%8B)\n",
    "- データを取り扱う人間として相応しい倫理を身に着けている(データのねつ造、改ざん、盗用を行わないなど)\n",
    "- 普段業務で扱っているデータの発⽣トリガー・タイミング・頻度などを説明でき、また基本統計量を把握している\n",
    " - グループで話し合い"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 確率分布\n",
    "----\n",
    "- 標準正規分布の分散と平均がいくつかわかる\n",
    "- ５つ以上の代表的な確率分布を説明できる\n",
    " - 一様分布\n",
    " - ベルヌーイ分布\n",
    " - 二項分布\n",
    " - ポアソン分布\n",
    " - 幾何分布\n",
    " - 指数分布\n",
    " - 超幾何分布\n",
    " - 正規分布\n",
    "- $y=log_{a}(x)$の逆関数を説明できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推測統計\n",
    "---\n",
    "- 母（集団）平均が標本平均とは異なることを説明できる\n",
    "- 標本誤差とは何かを説明できる\n",
    "- ⼆項分布の事象もサンプル数が増えていくと中⼼極限定理により正規分布に近似されることを知っている\n",
    " - 平均の分布が正規分布→和の分布も正規分布、二項分布はベルヌーイ分布の和→二項分布もサンプル数が増えていくと正規分布で近似できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回帰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 単回帰\n",
    "---\n",
    "-  単回帰分析について最小⼆乗法、回帰係数、標準誤差の説明ができる\n",
    " - 標準誤差はMCMCサンプルを使って、データ処理しながら把握\n",
    "- 相関関係と因果関係の違いを説明できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ロジスティック回帰\n",
    "---\n",
    "- 名義尺度の変数をダミー変数に変換できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### クラスタリング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### クラスタリングとは\n",
    "---\n",
    "- 教師あり学習の分類モデルと教師なし学習のグループ化の違いを説明できる\n",
    "- 判別分析とクラスター分析の概要や使い方を説明できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-means\n",
    "---\n",
    "- ボロノイ図の概念と活用方法を説明できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean-shift\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 階層的クラスタリング\n",
    "---\n",
    "- 階層クラスター分析と非階層クラスター分析の違いを説明できる\n",
    "- 階層クラスター分析において、デンドログラムの⾒方がわかり、適切に解釈できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データハンドリング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データ取得\n",
    "---\n",
    "- 仮説や既知の問題が与えられた中で、必要なデータにあたりをつけ、入手できる\n",
    "- 扱うデータが、構造化データ（顧客データ、商品データ、在庫データなど）なのか非構造化データ（雑多なテキスト、音声、画像、動画など）なのか判断できる\n",
    "- ER図を読んでテーブル間のリレーションシップを理解できる\n",
    "- データや事象の重複に気づくことができる\n",
    "- SQLで簡単なSELECT文を記述・実⾏できる（副問合せを含まない、2テーブル程度の結合と簡単なWHERE条件を含むSELECT文）\n",
    "- データベースから何らかのデータ抽出⽅法を活用し、小規模なExcelのデータセットを作成できる\n",
    "- 数十万レコードのデータに対して、条件を指定してフィルタリングできる（特定値に合致する・もしくは合致しないデータの抽出、特定範囲のデータの抽出、部分文字列の抽出など）\n",
    "- 数十万レコードのデータに対して、レコード間で特定カラムでのソートができる。また、数千レコードのデータに対して、カラム間でソートできる\n",
    "- 数十万レコードのデータに対して、単一条件による内部結合、外部結合、自己結合ができる。また、UNION処理ができる\n",
    "- 数十万レコードのデータに対して、ランダムまたは一定間隔にデータを抽出できる\n",
    "- サンプリングやアンサンブル平均によって適量にデータ量を減らすことができる\n",
    "- 加⼯・分析処理結果をCSV、XML、Excelなどの指定フォーマット形式に変換してエクスポートできる\n",
    "- データ取得用のWeb API（REST）やWebサービス（SOAP）などを用いて、必要なデータを取得できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データ加工\n",
    "---\n",
    "- 数十万レコードのデータを集計して、合計や最⼤値、最小値、レコード数を算出できる\n",
    "- 数十万レコードのデータに対して、規定されたリストと照合して変換する、都道府県名からジオコードに変換するなど、ある値を規定の別の値で表現できる\n",
    "- 数十万レコードのデータに対する四則演算ができ、数値データを日時データに変換するなど別のデータ型に変換できる\n",
    "- 標準化とは何かを知っていて、適切に標準化が⾏える\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 外れ値・異常値・欠損値\n",
    "---\n",
    "- 外れ値・異常値・⽋損値とは何かそれぞれ知っていて、指示のもと適切に検出と除去・変換などの対応ができる\n",
    "- 数十万レコードのデータに対して、NULL値や想定外・範囲外のデータを持つレコードを取り除く、または既定値に変換できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 課題\n",
    "---\n",
    "- 通常見受けられる現象の場合において、分析結果の意味合いを正しく言語化できる\n",
    "- ビジネス観点で仮説を持ってデータをみることの重要性と、仮説と異なる結果となったときにそれが重大な知見である可能性を理解している\n",
    "- 指⽰に従ってスケジュールを守り、チームリーダーに頼まれた自分の仕事を完遂できる \n",
    "- 自分の担当する業界について、市場規模、主要なプレーヤー、支配的なビジネスモデル、課題と機会について説明できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データサイエンス中級\n",
    "---\n",
    "分析結果の妥当性を保証できる  \n",
    "分析の専門分野を持つ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数学"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 行列分解\n",
    "---\n",
    "- ⾏列分解（非負値⾏列因⼦分解、特異値分解）をツールを使って実⾏でき、その結果を正しく解釈できる\n",
    "- レコメンデーション業務の要件から適切な協調フィルタリングロジック（ユーザベース、アイテムベースなど）の選定を⾏うことができる\n",
    " - 非負値行列分解と絡めて\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ把握"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 集計・数値要約\n",
    "---\n",
    "- 多重（質問間）クロス表などを駆使して、データから適切なインサイトを得ることができる\n",
    "- 抽出したい意味にふさわしい軸・層化の粒度、順番を考慮して軸のきざみや層化方法を選択できる \n",
    "- ⽣データを眺めて、どのような切り口で集計・⽐較すればデータの理解や事実の把握につながるか検討できる\n",
    "- 分析要件や各変数の分布などをふまえて、必要に応じて量的変数のカテゴライズを設計・実⾏できる\n",
    "- 統計量を使うことで、データの読み取りたい特徴を効果的に可視化できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### グラフ表示\n",
    "---\n",
    "- 特異点を明確にする、データ解析部門以外の方にデータの意味を正しく伝える、現場の作業を⽀援するといった可視化の役割・方向性を判別できる\n",
    "- 適切な情報（意味）を押さえた上で、デザイン性を⾼めるための要件提示ができる\n",
    "- 積極的に統計情報を収集しているとともに、表現に惑わされず数字を正当に評価できる（原点が0ではないグラフ、不当に誇張されたグラフなど）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 多変量\n",
    "---\n",
    "- 1〜3次元の図表を拡張した多変量の⽐較（平⾏座標、散布図⾏列、テーブルレンズ、ヒートマップなど）を適切に可視化できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 地理情報\n",
    "---\n",
    "- GPSデータなどを平面地図上に重ね合わせた可視化ができる\n",
    "- 挙動・軌跡の可視化ができる（店舗内でのユーザーの回遊やEye trackingなど）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ネットワーク構造\n",
    "---\n",
    "- ネットワーク構造、グラフ構造、階層構造などの統計的な関係性の可視化ができる\n",
    " - NetworkX\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 統計的仮説検定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### t検定\n",
    "---\n",
    "- 点推定と区間推定の違いを説明できる\n",
    "-  帰無仮説と対⽴仮説の違いを説明できる\n",
    "- 第1種の過誤、第2種の過誤、p値、有意水準の意味を説明できる\n",
    "- 片側検定と両側検定の違いを説明できる\n",
    "- t検定を理解して、パラメトリックな2群の検定を活用することができる\n",
    "- 統計値（代表値の指標、バラツキの指標、有意性の指標、関係式）を正しく読み、回帰式や移動平均線に意味付けできる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 対応のない2群の検定\n",
    "---\n",
    "- 対応のあるデータと対応のないデータの違いを説明できる\n",
    "- ２群の平均値の差の検定⼿法を知っている\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分割表の検定\n",
    "---\n",
    "- カイ⼆乗検定、フィッシャーの直接確率検定を理解して、分割表における群間の関連性の検定を活用することができる\n",
    "- 複数のA/Bテストの統計的結果を踏まえ、デザイン等の最適化を⾏う⼿法を回すことができる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 検定力分析\n",
    "---\n",
    "- 調査に求められる信頼水準・誤差率から必要となるサンプル数を試算できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テスト・バリデーション\n",
    "---\n",
    "- 過学習とは何か、それがもたらす問題について説明できる\n",
    "- 「教師あり学習」「教師なし学習」「強化学習」の違いを理解しており、データの内容や学習⼿法に応じて適切な学習データ、テストデータ、検証データ（チューニング用データ）を作成できる\n",
    "- ホールドアウト法、交差確認法などを用いて、モデルの汎化能⼒評価ができる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回帰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 重回帰\n",
    "---\n",
    "- 重回帰分析において偏回帰係数と標準偏回帰係数、重相関係数について説明できる\n",
    "- 重回帰分析において多重共線性の対応ができ、適切に変数を評価・除去して予測モデルが構築できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 正則化\n",
    "---\n",
    "- 回帰予測モデルの検討において、過学習を防止するためL1正則化（Lasso回帰）、L2正則化（Ridge回帰）を適切に適用できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 決定木\n",
    "---\n",
    "- 決定⽊分析においてCHAID、C5.0などのデータ分割のアルゴリズムの特徴を理解し、適切な方式を選定できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ロジスティック回帰\n",
    "---\n",
    "- 線形回帰分析が量的な変数を予測するのに対して、ロジスティック回帰分析は何を予測する⼿法か（発⽣確率予測など）を説明でき、実際に使用できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### サポートベクターマシン\n",
    "---\n",
    "- 分析対象に応じて、線形の判別分析モデルと非線形の判別分析モデルを適切に使い分けることができる\n",
    "- サポートベクターマシンによる分析を、統計解析ツールを使って実⾏でき、その結果を解釈できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ナイーブベイズ\n",
    "---\n",
    "- 形態素解析や係り受け解析のツールを適切に使い、基本的な⽂書構造解析を⾏うことができる\n",
    " - MeCab, JUMAN++, CaboCha\n",
    "- TF-IDFやcos類似度などの基本的なアルゴリズムを使い、単語ベクトルの作成や⽂書群の類似度計算を⾏うことができる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル評価・選択\n",
    "---\n",
    "- 重回帰や判別を実⾏する際に変数選択⼿法の特徴を理解し、適用できる\n",
    "- ROCカーブを用いてモデルの精度を評価できる\n",
    "-  混同⾏列（正誤分布のクロス表）を用いてモデルの精度を評価できる\n",
    "- MSE（Mean Square Error）、Accuracy、Precision、Recall、F値といった評価尺度を理解し、実際の精度評価を⾏うことができる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 高度な予測(教師あり学習)手法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### アンサンブル学習\n",
    "---\n",
    "- アンサンブル学習（Random Forest、勾配ブースティングマシン、バギング）による分析を、統計解析ツールを使って実⾏でき、その結果を正しく解釈できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ニューラルネットワーク\n",
    "---\n",
    "- 分析要件に応じ、量的予測のためのモデリング⼿法（重回帰、決定⽊、ニューラルネットワークなど）の選択とパラメータ設定、結果の評価、チューニングを適切に設計・実施・指示できる\n",
    "- ニューラルネットワークの基本的な考え方を理解し、出⼒される「ダイアグラム」の⼊⼒層、隠れ層、出⼒層の概要を説明できる\n",
    "- ニューラルネットワークによる分析を、統計解析ツールを使って実⾏でき、その結果を正しく解釈できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ベイジアンネットワーク\n",
    "---\n",
    "- ベイジアンネットワーク分析結果から目的事象の事後確率を算出できる\n",
    " - Edward, Pyro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### クラスタリング\n",
    "\n",
    "- [The 5 Clustering Algorithms Data Scientists Need to Know](https://www.kdnuggets.com/2018/06/5-clustering-algorithms-data-scientists-need-know.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-means\n",
    "---\n",
    "- k-means法は局所最適解であるため初期値問題があることを理解し、適切な初期値を設定して分析を⾏える\n",
    "- 非階層クラスター分析において、分析目的に合致したクラスター数を決定することができる\n",
    "- 各種距離関数（ユークリッド距離、マンハッタン距離、cos類似度など）を理解し、目的に合致した最適な⼿法で分析できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean-shift\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 階層的クラスタリング\n",
    "---\n",
    "- 階層クラスター分析における代表的なクラスター間距離（群平均法、Ward法、最⻑⼀致法など）の概念を理解し、目的に合致した最適な⼿法で分析できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 時系列データ\n",
    "---\n",
    "- 時系列データの時点差での相関関係を、系列相関やコレログラムを利用して評価ができる\n",
    "- 時系列データに対し、ツールを使用して、分析結果の⽐較を⾏い、適切なモデルを選択できる（自己回帰モデル、移動平均モデル、ARIMA、SARIMA、指数平滑法など）\n",
    "- 時系列分析は少なくとも３つの要素の視点をもって⾏うべきことを理解している（⻑期トレンド、季節成分、その他周期性など）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分散分析？(ベイズ統計で代用するかも)\n",
    "---\n",
    "- 様々な分散分析の考え方（⼀元配置、多重⽐較、⼆元配置）を理解して、パラメトリックな多群の検定を活用することができる\n",
    "- ウィルコクソン検定（マンホイットニーのU検定）を理解して、ノンパラメトリックな2群の検定を活用することができる\n",
    "- クラスカル・ウォリス検定を理解して、ノンパラメトリックな多群の検定を活用することができる\n",
    "- ベイズ統計と頻度論による従来の統計との違いを、尤度、事前確率、事後確率などの用語を用いて説明できる\n",
    "- マルコフ連鎖の特徴を理解し、MCMC（マルコフ連鎖モンテカルロ法）シミュレーションをツールを用いて実装できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 次元削減(ポジショニングマップ)・潜在変数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 主成分分析\n",
    "---\n",
    "- データの持つ分散量の観点で、⾼次のデータを主成分分析（PCA）などにより1〜3次元のデータに変換できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### コレスポンデンス分析\n",
    "---\n",
    "- コレスポンデンス（対応）分析と数量化3類の類似点と違いを説明出来る\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 因子分析\n",
    "---\n",
    "- 因⼦分析における、因⼦負荷量や因⼦軸の回転について説明できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分散・共分散構造分析(構造方程式モデリング)\n",
    "---\n",
    "- パス解析において、変数間の因果関係をパス図を用いて説明できる\n",
    "- ツールを用いて共分散構造分析（構造方程式モデリング：SEM）を⾏い、観測変数・潜在変数の因果関係を説明できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### コンジョイント分析\n",
    "---\n",
    "- コンジョイント分析を用いて効用値と寄与率のグラフを描くことができる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 多次元尺度構成法\n",
    "---\n",
    "- 適切な類似度を設定した上で、多次元尺度構成法を用いてポジショニングマップを描くことができる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最適化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 線形計画法\n",
    "---\n",
    "- 線形計画法について、説明することができる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 多腕バンディットアルゴリズム\n",
    "---\n",
    "- ⼀定の制約下で最適解の識別と報酬の最⼤化がともに求められ、かつ報酬分布が時間経過で変化するような問題に対して、多腕バンディットアルゴリズムを適用・実装できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ取得\n",
    "---\n",
    "- 調査対象の⺟集団の規模・特性や調査コストに応じて、多段階抽出法や層化抽出法など適切な標本抽出方法を計画できる\n",
    "- 属性数と水準数が決まれば適切な直交表を選択し実験計画ができる\n",
    "- 扱ったことのない新たなデータに内容の不明な項目があっても、⽣データの閲覧や集計を通して何の項目かあたりをつけられる\n",
    "- 扱っているデータの関連業務の知識と分析目的を踏まえて、どんな説明変数が効きそうか、あたりをつけて洗い出し、構造的に整理できる\n",
    "- 分析目的とデータの量・質を踏まえて、想定されるメッセージと統計的観点から適切な集計単位とサンプリング率を決定できる\n",
    "- Webクローラーの仕組みを理解し使いこなせる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データハンドリング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 外れ値・異常値・欠損値\n",
    "---\n",
    "- 各変数の分布・⽋損率などをふまえて、外れ値・異常値・⽋損値の対応を決定できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### まとめ・課題\n",
    "---\n",
    "- 分析の目的と用いるデータの種類から、正規分布を前提とした多変量解析の適切な⼿法を選択できる\n",
    "- 分析で解くべき課題か否かを判断できる\n",
    "- 各種の解析⼿法（主成分分析、クラスター分析、決定⽊分析など）の結果を解釈し、意味合いを適切に表現・説明できる\n",
    "- 分析結果が当初の目的を満たしていない場合に、問題を正しく理解し、目的達成に向けて必要な分析⼿順を追加・変更できる\n",
    "- ビジネスではスピード感がより重要であることを認識し、時間と情報が限られた状況下でも、言わば「ザックリ感」を持って素早く意思決定を行うことができる\n",
    "- 作業ありきではなく、本質的な問題(イシュー)ありきで行動できる\n",
    "- 分析で価値ある結果を出すためにはしばしば仮説検証の繰り返しが必要であることを理解し、粘り強くタスクを完遂できる\n",
    "- 論理的なプレゼンテーションができる\n",
    "- 最終的な結論に関わる部分や、ストーリーラインの骨格に大きな影響を持つ部分から着手するなど、取り組むべき分析上のタスクの優先度を判断できる\n",
    "- 担当する分析プロジェクトの分析結果を見て検討目的と合っているか再評価できる\n",
    "- 異なるスキル分野の専門家や事業者と適切なコミュニケーションをとりながら事業・現場への実装を進めることができる\n",
    "- 自⾝とチームメンバーのスキルを把握し、適切なプロジェクト管理ができる\n",
    "- ビジネス要件を整理し、分析・データ活⽤のプロジェクトを企画・提案することができる\n",
    "- 仮説思考を用いて、論点毎に分析すべき点を識別できる\n",
    "- 因果関係に基づいて、ストーリーラインを作れる (観察⇒気づき⇒打ち手、So What?、Why So?など)\n",
    "- 統計手法による閾値に対してビジネス観点で納得感のある調整ができる(年齢の刻み、商品単価、購入周期を考慮した量的変数のカテゴライズなど)\n",
    "- ビジネス上の意味を捉えるために、特異点、相違性、傾向性、関連性を見出した上で、ドメイン知識を持つ人に適切な質問を投げかけられる\n",
    "- 分析的検討に基づき、担当業務に対する必要なアクション、改革案を整理して結論を導くことができる\n",
    "- 現場に実装する際、現場での実行可能性を考慮し適切に対応できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データサイエンス上級\n",
    "---\n",
    "分散処理が必要なレベルの大規模データを扱える  \n",
    "前例のないような未知の状況にも対応できる  \n",
    "最先端の手法を開発・実装できる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 課題設定\n",
    "---\n",
    "素案  \n",
    "リーンスタートアップにおけるプロダクトマーケットフィットとマーケティングリサーチによって顧客のニーズにあった商品開発を行うこと、スタートアップで製品よりも創業者が重要であることと成熟事業でも品質管理・戦略より人材が重要であることなどを通して、リーンはデータが少ない状態でベイズ更新を繰り返し精度を上げていくアプローチであり従来型の戦略が十分なデータに基づいた分析であるように、同じ対象に対してデータ量に基づいて異なる統計手法を適用する具体化であると捉え、確率的なものの考え方を様々な分野に適用することの有用性を確認する。  \n",
    "中級までよりも広い視点からデータ活用を考えることの重要性を指摘する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## スキルチェックリスト"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データサイエンス"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 初級"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 必須\n",
    "- 順列や組合せを式 $_{n}P_{r},\\ _{n}C_{r}$を用いて計算できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 選択\n",
    "- 実験計画法の概要を説明できる\n",
    "- 適切な情報濃度を判断できる（データインク⽐など）\n",
    "- 端的に図表の変化をアニメーションで可視化できる（人口動態のヒストグラムが経年変化する様⼦を表現するなど）\n",
    "- スコープ、検討範囲・内容が明快に設定されていれば、必要なデータ、分析⼿法、可視化などを適切に選択できる\n",
    "- データ項目やデータの量・質について、指示のもと正しく検証し、結果を説明できる\n",
    "- 想定に影響されず、分析結果の数値を客観的に解釈できる\n",
    "- 機械学習にあたる解析⼿法（Random Forestなど）の名称を3つ以上知っており、⼿法の概要を説明できる\n",
    "- 指示を受けて機械学習のモデルを使用したことがあり、どのような問題を解決することができるか理解している\n",
    "-  時系列データについて説明ができる（時系列グラフ、周期性、移動平均など）\n",
    "- 形態素解析や係り受け解析の概念を説明できる\n",
    "- 画像のデジタル表現の仕組みと代表的な画像フォーマットを知っている\n",
    "- 画像に対して、目的に応じた適切な色変換や簡単なフィルタ処理などを⾏うことができる\n",
    "- 動画のデジタル表現の仕組みと代表的な動画フォーマットを理解しており、動画から画像を抽出する既存方法を使うことができる\n",
    "- wavやmp3などの代表的な⾳声フォーマットを知っている\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 中級"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 必須\n",
    "- 主成分分析と因⼦分析の違いや使い分けを説明できる\n",
    "- 解くべき課題がフレーミングされていれば、必要なデータ、分析⼿法、可視化などを適切に選択できる\n",
    "- 複数のグラフや集計表で構成されているレポートに対して、全体として集計ミスや不整合が起きていないかチェックできる\n",
    "- データを俯瞰して、変化をすみやかに察知するとともに、変化が誤差の範囲かどうか判断できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 選択\n",
    "-  正準相関分析を説明、活用できる\n",
    "- 加⼯データに不具合がないか自分でテストを設計し、検証できる\n",
    "- 膨⼤な属性を持つテーブルから目的に有用な属性を選択できる\n",
    "- データ項目やデータの量・質の検証方法を計画・実⾏し、その結果をもとにその後の分析プロセスを⽴案・修正できる\n",
    "- ピリオドグラムにおいて、FFT（Fast Fourier Transform）など計算量を抑制する方法により、ピリオドグラムの計算ができる\n",
    "- 画像の処理や解析において、効果的なパターン検出や画像特徴抽出などを既存⼿法から選ぶことができる\n",
    "- 画像の処理や解析において、既存のAPI化したクラウドサービスなどを目的に即して、選定・活用することができる\n",
    "- ⾳声データから、分析目的にあった波形データの抽出やノイズの除去をすることができる\n",
    "- ⾳声認識や本人認証、感情分析などの代表的な⾳声処理分野について理解し、用いられる分析⼿法を説明することができる\n",
    "- 離散型・連続型シミュレーションについて、説明できる（モンテカルロ、ヒストリカル、Agentベースなど）\n",
    "- 凸関数および、凸計画問題の条件や特徴を説明できる\n",
    "- 連続最適化問題（制約なし）において、使用可能なアルゴリズムを説明することができる（ニュートン法、最急降下法など）\n",
    "- 連続最適化問題（制約あり）において、使用可能なアルゴリズムを説明することができる（ラグランジュ未定乗数法、内点法、逐次2次計画法など）\n",
    "- 組み合わせ最適化問題において、代表的な解法の概念を説明することができる（厳密解法（分枝限定法、動的計画法、切除平面法）、近似解法（局所探索、貪欲法など）、メタヒューリスティック解法（遺伝的アルゴリズム、タブーサーチなど））\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 上級"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 必須\n",
    "- 分析に必要なデータを想定し、現在取得可能なデータの量・質で分析に耐えうるか、分析目的が達成可能であるかを判断できる\n",
    "- 複数のデータを多元的かつ⼤局的に俯瞰して、⼤きな動きや本質的な事実を⾒抜くことができる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 選択\n",
    "- 予測アルゴリズムに応じ、目的変数と説明変数に対する必要な変数加⼯処理を設計、実施できる\n",
    "- 予測モデル構築において頑健性を維持するための具体的な方法を設計、実施できる\n",
    "- 尤度と最尤推定についての説明ができる（尤度関数、ネイマンの分解定理、順序統計量）\n",
    "- 予測対象データの分布をみて、分布形状に適合した計算式の非線形回帰モデルを構築できる\n",
    "- ロジスティック回帰分析において回帰パラメータとオッズ⽐の関係について説明できる\n",
    "- ロジスティック回帰分析を⾏う際に、最小2乗法ではなく最尤法を使う際の利点（回帰誤差が近似的に正規分布しなくても適用できるなど）を説明し、適用することができる\n",
    "- 目的（予測・真のモデル推定など）に応じて、適切な損失関数とモデル選択基準（AIC（⾚池情報量規準）、BIC（ベイズ情報量規準）、MDL（最小記述⻑）など）を選択し、モデル評価ができる\n",
    "- データと分析要件から、モデル精度のモニタリング設計・実施と劣化が⾒込まれるモデルに対するリモデルの設計ができる\n",
    "- 当該分野に則したベイズ統計に基づくアルゴリズムを理解し、モデルを構築できる\n",
    "- 距離の公理を知っており、距離の公理を満たさない場合（［1-cos類似度］など）のクラスター分析を適切に⾏える\n",
    "- k-meansの派⽣⼿法（x-means、k-means++、ファジィk-meansなど）を理解し、目的に合致した最適な⼿法で分析できる\n",
    "- k-meansとカーネルk-means（非線形クラスタリング）、スペクトラルクラスタリングの違いを理解し、試⾏の中で最適な⼿法を選択・実⾏できる\n",
    "- 自己組織化マップ（SOM）、Affinity Propagation、混合分布モデル、ディリクレ過程混合モデルを理解し、試⾏の中で最適な⼿法を選択・実⾏できる\n",
    "- 反復⼦ニューラルネットワーク（オートエンコーダ）、One-class SVM（Support Vector Machine）、マハラノビス距離を用いた異常検知の⼿法を理解し、試⾏の中で最適な⼿法を選択・実⾏できる\n",
    "- 空間的自己相関の⼿法を用いて空間的な類似性を数値化できる\n",
    "- ⾏列分解（非負値⾏列因⼦分解、特異値分解）を、目的に応じてパラメータを最適化して分析できる\n",
    "- 加⼯データの統計的な俯瞰によって不具合の早期発⾒ができるとともに、統計的観点で次ステップの解析に耐えうるデータであるか評価できる\n",
    "- データ量が膨⼤で構造が捉えにくい場合や、アウトプットが想像しにくい場合であっても、可視化の役割・方向性を判断できる（ビッグデータ中の要素間の関連性をダイナミックに表現する、細部に⼊りきらずに問に対して答えを出すなど）\n",
    "- 非構造データから分析の軸になりうる候補を抽出し、付加すべき属性候補を適切に出せる\n",
    "- 非線形（⾼次の曲線、渦状の分布など）のデータであっても、⾼次のデータの次元を、次元圧縮（1〜3次元のデータに変換）して、特徴（データの総分散量および各データの位置関係）を損なわずに可視化できる\n",
    "- ネットワーク構造、グラフ構造などの表現において、ノードとエッジが増えすぎて特徴抽出が困難であっても、データの絞り込みや抽象度を上げることで適切に可視化できる\n",
    "- データ量が膨⼤（ペタバイト以上）なために、処理しきれず描画できない規模のデータに対しても、適度なデータや情報の抽出（間引き）、クラスタリングなどにより可視化しうる状態にデータを加⼯できる\n",
    "- ⼤規模なデータへのリアルタイムな可視化が求められる場合であっても、特異点の抽出や次元圧縮を通じてデータを圧縮し、リアルタイム表示できる\n",
    "- ⼤規模なデータへのリアルタイムな可視化が求められる場合であっても、データの分割転送、復元を通じて可視化できる\n",
    "- 人体、標⾼を持つ地図、球面などの上にデータを重ね合わせた可視化ができる\n",
    "- 地図上で同時に動く数百以上のポイントにおける時間変化を動的に表現できる（多地点での風の動き、⾶⾏物の軌跡など）\n",
    "- 分類系の分析において、分布傾向から原因を追究、活用（分類に応じたDM発送による反応率の向上など）、ドリルダウンを計画し主導できる\n",
    "- 予測系の分析において、関連性、特異点、変曲点から原因を追究、活用（予測結果に基づく発注管理など）を計画し主導できる\n",
    "- 関連系の分析において関連が⾼い/低い原因、活用（リコメンドなど）、ドリルダウンを計画し主導できる\n",
    "- 複数の事業や課題にまたがっていても、必要なデータ、分析⼿法、可視化などを適切に選択し作業⼿順に落とし込める\n",
    "- 複数のアプローチの組み合わせでしか解けない課題であっても、その解決までの道筋を設計できる\n",
    "- 数字やデータの検証のために、何と⽐較するべきかすみやかに把握し、収集・利用できる（業務データや過去に接触した統計情報の想起・活用を含む）\n",
    "- 多数のグラフ、集計表、外部の統計情報、⾼度なデータ解析⼿法を用いた解析結果などを含むレポートに対して、不整合が起きていないか、妥当性の⾼い論理構造であるかチェックできる\n",
    "- データの変化から起きている事象の背景を構造的に推察し、仮説を⽴て、検証方法を企画実⾏できる\n",
    "- データを⼊⼿する前に、存在するであろうデータとその分布を想定して基礎俯瞰の方向性やその結果の想定ができ、それを前提とした解析方法の検討・ラフ設計をすることができる\n",
    "- 扱ったことのない新たなデータであっても、ER図やテーブル定義、⽣データなどを⾒ることによってデータの発⽣源や⽋損値の意味などのあたりをつけられる\n",
    "- 分析目的とデータの量・質に加えて、想定しているメッセージ、深掘りの方向性・可能性、処理負荷、データ処理フローなども総合的に踏まえた最適な集計単位とサンプリング率を決定できる\n",
    "- 課題やデータ型に応じて、サポートベクターマシンの適切なモデルを選定し、目的に応じてアルゴリズムの調整や設計ができる\n",
    "- 課題やデータ型に応じて、アンサンブル学習（Random Forest、勾配ブースティングマシン、バギング）の適切なモデルを選定し、目的に応じてアルゴリズムの調整や設計ができる\n",
    "- CNN、RNN/LSTMなどの深層学習（ディープラーニング）の主要方式の特徴を理解し、目的に応じて適切に選定できる\n",
    "- 深層学習（ディープラーニング）の実装において、予想精度を向上するため、層の種類（プール、畳み込み）、層数、ニューロン数、活性化関数、学習回数などをチューニングできる\n",
    "- 過学習を回避する方法を設計・実施できる\n",
    "- ⾼次元データの取り扱いについて、次元の呪いを考慮し適切に次元削減できる\n",
    "- 機械学習等の最新の論⽂を理解し、必要とあれば自分で実装し評価できる\n",
    "- バイアスとバリアンスの関係を理解し、モデル選定を適切に⾏える\n",
    "- 状態空間モデルにおいて、カルマンフィルタを用いて、観測値から⽋測値の補間をし、予測モデルを構築できる\n",
    "- 非線形・非ガウス型状態空間モデルにおいて、モンテカルロ・フィルタを用いて、複雑な時系列システムの予測モデルを構築できる\n",
    "- 形態素解析・構⽂解析・固有表現抽出のアルゴリズムを理解し、使いこなせる\n",
    "- N-gram⾔語モデルの構築方法と代表的なスムージングアルゴリズムを理解し、使いこなせる\n",
    "- 索引型の全⽂検索の仕組み（転置インデックス、スコアリング、関連性フィードバック）を理解し、使いこなせる\n",
    "- Trie、Suffix Arrayなどの代表的な⾼速⽂字列検索アルゴリズムを理解し、使いこなせる\n",
    "- 潜在的意味解析（LSA）の仕組みを理解し、使いこなせる\n",
    "- データの特性に合わせ、適切な⾔語処理アルゴリズムを選択し、誤り分析、辞書作成などを⾏い、成果を最⼤化することができる\n",
    "- トピックモデル、サポートベクターマシン（SVM）などの⽂書分類⼿法を理解し、実⾏できる\n",
    "- 再帰型ニューラルネットワーク（RNN）、⻑期短期記憶（LSTM）などを用いたニューラルネット型⾔語モデルを理解し使いこなせる\n",
    "- 隠れマルコフモデル（HMM）などを用いた系列ラベリング⼿法を理解し使いこなせる\n",
    "- スキップグラム（Skip-gram）などの分散表現モデルを理解し使いこなせる\n",
    "- 物体検出・識別などの画像処理⼿法に関して、適切な論⽂などの⽂献を参考に実装し評価できる\n",
    "-　画像・動画処理を⾏う環境に合わせて適切な実装・⼿法を選ぶことができる\n",
    "- 動画の自動解析⼿法の現況について理解し、適切な専門家のサポートの元で実装を検討できる\n",
    "- ケプストラム分析やLPC（線形予測分析）などの代表的な⾳声信号分析⼿法を理解し、使いこなすことができる\n",
    "- ⾳声認識や認証・感情分析などの目的に合わせて、パラメータ調整や⼿法変更、⾔語モデル・⾳響モデルなどを差し替え、モデル構築・精度評価をすることができる\n",
    "- データ同化の概念を理解し、実⾏できる（データを用いてシミュレーション内の不確実性を減少させる計算技法など）\n",
    "- シミュレーションにおける問題を理解し、対処を考えることができる（初期条件・境界条件・パラメータの不確実性、データ分布の不均⼀性、実験計画の最適性など）\n",
    "- MCMC（マルコフ連鎖モンテカルロ法）における各種アルゴリズム（メトロポリスヘイスティングス法、ギブスサンプラー、ハミルトニアン・モンテカルロ法など）について理解し、活用できる\n",
    "- ビジネス課題にあわせて、変数、目的関数、制約を定式化し、線形・非線形を問わず、最適化モデリングができる\n",
    "- 代表的な最適化問題に関して、モデリングを⾏い、ソルバーを使い、最適化できる（ナップザック問題、ネットワークフロー問題、巡回路問題など）\n",
    "- バッチ勾配降下法、確率的勾配降下法、ミニバッチ勾配降下法の違いを説明でき、勾配降下法の複数のアルゴリズムを、目的に応じて使い分けることができる（Momentum、Adamなど）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データエンジニアリング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 初級"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 必須\n",
    "- 対象プラットフォームが提供する機能（SDKやAPIなど）の概要を説明できる\n",
    "- 同種のデータを統合するシステムを設計できる\n",
    "- 業務で使用するシステムのデータのライフサイクル（いつ、どんなデータが発生し、いつまで保持されているのかなど）を把握して、論理モデルを作成できる\n",
    "- Hadoop・Sparkの分散技術の基本的な仕組みと構成を理解している\n",
    "-  加⼯・分析処理結果を、接続先DBのテーブル仕様に合わせてレコード挿⼊できる\n",
    "- FTPサーバー、ファイル共有サーバーから必要なデータファイルをダウンロードして、Excelなどの表計算ソフトに取り込み活用できる\n",
    "- 小規模な構造化データ（CSV、RDBなど）を扱うデータ処理（抽出・加⼯・分析など）を、設計書に基づき、プログラム実装できる\n",
    "- セキュリティの3要素（機密性、可用性、完全性） について具体的な事例を用いて説明できる \n",
    "- マルウェアなどによる深刻なリスクの種類（消失・漏洩・サービスの停⽌など）を常に意識している\n",
    "- 暗号化されていないデータは、不正取得された際に容易に不正利用される恐れがあることを理解し、データの機密度合いに応じてソフトウェアを使用した暗号化と復号ができる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 選択\n",
    "- サーバー1〜10台規模のシステム構築、システム運用を指⽰書があれば実⾏できる\n",
    "- 数十万レコードを持つデータベースのバックアップ・アーカイブ作成など定常運用ができる\n",
    "- オープンデータ活用目的でExcelを使った分析システムの要件定義が⾏える\n",
    "- 対象プラットフォームに用意された機能（HTTP、FTP、SSHなど）を用い、データを収集先に格納するための機能を実装できる\n",
    "- 正規化⼿法（第一正規化〜第三正規化）を用いてテーブルを正規化できる\n",
    "- DWHアプライアンス（Oracle Exadata、IBM Pure Data/Netezza、Teradataなど）に接続し、複数テーブルを結合したデータを抽出できる\n",
    "- NoSQLデータストア（HBase、Cassandra、Amazon DynamoDB、Cloudant、Azure DocumentDBなど）にAPIを介してアクセスし、新規データを登録できる\n",
    "- クラウド上のストレージサービス（Amazon S3、Google Cloud Storage、Bluemix Cloud Obect Storageなど）に接続しデータを格納できる\n",
    "- BIツールのレポート編集機能を用いて新規レポートを公開できる\n",
    "- BIツールの自由検索機能を活用し、必要なデータを抽出して、グラフを作成できる\n",
    "- JSON、XMLなど標準的なフォーマットのデータを受け渡すために、APIを使用したプログラムを設計・実装できる\n",
    "- OS、ネットワーク、アプリケーション、データに対するユーザーごとのアクセスレベルを⼿順に従い設定できる\n",
    "- なりすましや偽造された文書でないことを証明するために電子署名と公開鍵認証基盤（PKI：public key infrastructure）が必要であることを理解している\n",
    "- ハッシュ関数を用いて、データの改ざんを検出できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 中級"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 必須\n",
    "- 数千万レコードのデータを保持するシステムにおいてデータの重要性や分析要件に則したシステム構築、初期データ投⼊⽅法、システム運用の要件定義が⾏える\n",
    "- 社内分析者向けのRDBMS、NoSQL、ETL、Visualizationなど単一コンポーネントのユーザー利用機能設計が⾏える\n",
    "- ビジネスプロセスを理解・整理して、データフロー図、論理データモデル、ER図、テーブル定義書を作成できる\n",
    "- 分析プログラムのロジックと処理⼿順を理解した上で正しい分析結果を出⼒しているか検証ができる\n",
    "- SQLの構文を一通り知っていて、記述・実⾏できる（DML・DDLの理解、各種JOINの使い分け、集計関数とGROUP BY、CASE文を使用した縦横変換、副問合せやEXISTSの活用など）\n",
    "- データ匿名化の⽅法を理解し、匿名化⽅法（ハッシュ化、マスキング、k-匿名化など）に応じた加⼯処理を設計できる \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 選択\n",
    "- 顧客管理など分析システムの運用（異常検知、フェイルオーバー、バックアップ、リカバリー処理、開始・停⽌処理）の⼿順書作成や要件定義が⾏える\n",
    "- 数千万レコードのデータを保持するシステムのキャパシティ要件（データ容量）と必要処理性能（スループット）を定義できる\n",
    "- HTTPを活用したオープンAPIと分析システムのサーバー環境及びデータベースの連携設計ができる\n",
    "- ソフトウェア開発プロジェクトの管理⽅法、設計、テスト⽅法を理解した上で、データ管理・分析システムを要求定義することができる\n",
    "- 深層学習（ディープラーニング）の学習を高速化するために、GPU（GPGPU）環境を設計・実装できる\n",
    "- 対象プラットフォーム（iOS、Android、HEMSなど）におけるデータ取得の仕様（精度など）を理解しており、システム要件を満たせるか判断できる\n",
    "- 目的に適したログ取得項目を、対象プラットフォーム（iOS、Android、HEMSなど）で取得可能なデータを用いて設計できる\n",
    "- 対象プラットフォームにおけるバッテリー消費や通信速度などを含めたシステム要件を作成できる\n",
    "- データ収集対象の要件に応じて、MQTT（Message Queue Telemetry Transport）によるパブリッシュ/サブスクライブ型の通信を検討・実装できる\n",
    "- ネットワークプロトコルや暗号化などの通信技術を用い、通信のボトルネックと可用性（継続的に通信が成⽴していること）を考慮した上で、必要な通信機能を実装できる\n",
    "- 既存のサービスやアプリケーションに対して、有効な分析をするためのログ出⼒の追加仕様を整理することができる\n",
    "- データ保持ルール（データアクセス、性能、保持期間、セキュリティなど）に基づき、データベース・DWHの運用ルールを定義できる\n",
    "- 業務特性や基幹システムの特徴をもとに、検索で頻繁に使用するデータのキー（顧客IDなど）を想定し、インデックスを作成・設定できる\n",
    "- データ集計を高速化またはSQLを単純化するため、スタースキーマ、スノーフレークスキーマなどを用いたデータモデルを設計できる\n",
    "- 稼働中の複数のシステム間で発生するデータ項目の差異を、変換テーブルを活用して、埋めることができる\n",
    "- DWHに⼊れる元データ（基幹DBのデータなど）のキーに変更があった場合に、サロゲートキーやナビゲーションブリッジテーブルを用いて対応できる\n",
    "- DWHアプライアンス（Oracle Exadata、IBM Pure Data/Netezza、Teradataなど）の機能と特徴を理解し、適切な管理対象データを選定できる\n",
    "- 分散処理環境のディストリビューションを導⼊できる（Hortonworks、CDHなど）\n",
    "- Hadoopの得意な点、苦⼿な点を理解し、Hadoopにて管理すべきデータを選定できる\n",
    "- KVSの特性（集計・ソートが苦⼿、データの一貫性保証など）を理解し、KVSがデータストア要件を満たすかを判断できる\n",
    "- クラウド上のDWHサービス（Amazon Redshift、Google BigQuery、IBM dashDBなど）にデータをロードし公開できる\n",
    "- 正規表現を活用して条件に合致するデータを抽出できる（メールアドレスの書式を満たしているか判定をするなど）\n",
    "- フラットファイルやバイナリファイルに対するデータロードの前処理（クレンジング操作、禁則処理やバイナリ処理）ができる\n",
    "- 線形補間など、複数のレコードを考慮したクレンジング処理ができる\n",
    "- 数千万レコードのデータに対して、カラムナー型のデータに変換できる\n",
    "- 利用者の要件に合致したレポート（図、表）を、PDFやPostScriptなどの印刷用フォーマットで出⼒する変換機能を設計できる\n",
    "- BIツール用のサーバーを構築し、単一データソースのレポート用DBを設計・構築できる\n",
    "- データストア上のデータをメールやメッセージ（Webサービスなど）を用いてプッシュ配信するシステムのサーバー・ネットワーク・ソフトウェアの構成を設計できる\n",
    "- Webアプリケーションの実装において、WebSocketを用いてクライアント側にリアルタイムにデータ提供できる機能を設計できる\n",
    "- RSS、RDFや業界標準フォーマットなど要件に合致したデータ形式・配信形式で、情報提供するシステムのインターフェースを設計できる\n",
    "- Web API（REST）やWebサービス（SOAP）などを用いて、必要なデータを提供するシステムの公開インターフェースを設計できる\n",
    "- 連携対象システムの仕様に合わせて、ETLツールを用いたデータ変換、ファイル転送処理を実装できる\n",
    "- 非効率なループ処理の性能向上などのために、計算量やメモリを意識したプログラム実装ができる\n",
    "- データ型を意識したプログラム設計・実装ができる（C⾔語での性能・誤差を意識したデータ型の実装、Pythonでのエラー時のデータ型を意識したデバッグなど）\n",
    "- 異なるタイプの複数の処理を効率よく⾏うために、スクリプトを用いたプログラムを設計・実装できる（パイプライン処理のluigiなど）\n",
    "- GPU（GPGPU）を有効に活用できるライブラリを選択し、利用できる\n",
    "- SNSから抽出した非構造化データを、適切な⾔語やライブラリを選んでプログラム実装できる\n",
    "- HiveQLやSpark SQLを記述して、パーティションが切られているデータを適切に処理できる\n",
    "- Pigを記述して列数・内容の異なる⾏が混在しているデータセットやネスト構造を持つデータセットを処理できる\n",
    "- Scala⾔語を用いて、分散処理環境（Sparkなど）におけるロジックを設計・実装できる\n",
    "- DoS攻撃、不正アクセス、マルウェア感染や内部不正などのセキュリティインシデントが発覚した場合に既存のルールに基づき対応できる\n",
    "- OS、ネットワーク、アプリケーション、データに対するユーザーごとのアクセスレベルを設計できる\n",
    "- SQLインジェクションやバッファオーバーフロー攻撃の概要を理解し、防⽌する対策を判断できる\n",
    "- SSHやSSL/TLSなどのセキュアプロトコルの概要と必要性を説明できる\n",
    "-  DES、AES、RC4を用いたKerberos認証が使われる事例と仕組みを説明できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 上級"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 必須\n",
    "- サービス上のそれぞれの機能がどのデータに関連があるか把握し、分析機能追加やシステム変更の要件を整理できる\n",
    "- ⼊⼿可能なデータに加え、分析結果の品質・効果を向上させる新たなデータ⼊⼿⽅法を提案できる（IoTでの新設センサーの種類・配置場所・データ⼊⼿間隔など）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 選択\n",
    "- 数十億レコードのデータに対してリバランシングなども含めてシステム拡張⽅法や最適化の要件を整理できる\n",
    "- 扱うデータのデータ規模や機密性、分析要件を理解した上で、オンプレミスで構築するか、クラウド上で構築するかの要件を整理できる\n",
    "- 数十億レコード規模のデータに対し、HadoopやSparkなどを組み合わせた適切なシステム構成を設計できる\n",
    "- 組織を横断する多種多様なデータが混在する環境下でのデータ利活用ニーズに対して適切なシステム環境を設計・提案できる\n",
    "- 数十億レコードの内部データ（CRM、webログ、ユーザー購買データ）、外部データ（購⼊しているデータ、オープンデータ）を理解し、複数のデータソースを統合する要件を整理できる\n",
    "- KVS、カラム指向、ドキュメント指向などデータ構造の異なる複数のシステムからデータ取得と分析環境への連携が設計できる\n",
    "- 数十億レコードのデータを持つ業務要件やリソース負荷に応じて、データフローや管理機構の統合、またバッチ実⾏スケジュールの最適化について要件定義が⾏える\n",
    "- 全体システム化計画及び個別システム化構想・計画を具体化するために、全体最適の観点を持ちながら、対象とするデータ分析システムの開発に必要となる要件を整理することができる\n",
    "- データ活用戦略を正しく理解し、各種業務プロセスについての専門知識とシステムに関する知識を有し、双⽅を活用して、適切な要求定義が⾏える\n",
    "- 取得するデータが増えることを想定し、拡張性を考慮したクライアントアプリケーション（ロガーなど）を設計できる\n",
    "- プラットフォームの違いを吸収し、統一的にデータを取得するプログラムを実装できる\n",
    "- データ通信において、機能・性能の問題に対し根本原因を特定できるだけでなく、必要に応じて新規技術の適用を検討できる\n",
    "- 異種フォーマットが混在するデータを統合するシステムを設計できる\n",
    "- システム分析・業務分析をもとに、必要なデータフロー管理やジョブ管理ツールを選定・評価できる\n",
    "- 非正規化テーブルや一時テーブルなどを作成し、アプリケーションの処理速度を高速化できる\n",
    "- 分散クラスタ構成が構築可能なRDBMS製品（Oracle RAC、DB2 Pure Scaleなど）を用いてスケールアウト可能なオンプレミス構成を設計できる\n",
    "- Hadoop・Sparkの分散アーキテクチャを理解し、⼤容量データ処理のパフォーマンスチューニングができる\n",
    "- クラウド上のデータストアサービスが機能面・非機能面で対象業務に合致するかの評価を⾏い、採用可否を判断できる\n",
    "- 基盤設計において、どこのシステム要素にmemcachedなどのキャッシュ機能を採用すると処理が高速化されるか判断できる\n",
    "- リアルタイムに⼊⼒されるストリームデータから指定条件のイベントを即時に抽出する複合イベント処理（CEP）を実現するサーバー環境・構成を設計できる\n",
    "- リアルタイムに連続して⼊⼒されるストリームデータの加⼯・集計処理を⾏うにあたり、Storm等のリアルタイム分散フレームワーク適用の有効性を判断できる\n",
    "- 分散処理のフレームワーク（Spark、Tezなど）を用いてアプリケーションの計算処理を複数サーバーに分散させる並列処理システムを設計できる\n",
    "- データストアの技術動向に注目し、リレーショナルDBだけでなく、グラフDB・時系列DBなどの新規技術の検証・評価ができる\n",
    "- データ定義や実際の観測データの状況をもとに、名寄せ処理を設計・実装できる\n",
    "- ESB・EAIなどのデータ連携基盤を活用してシステム間のデータ連携（データ配信・交換）を⾏うインターフェースを設計できる\n",
    "- 最新の論文に発表された数式処理や機械学習ロジックをプログラム実装できる\n",
    "- GPU（GPGPU）環境において、演算速度を最適化するライブラリを有効に選択し、利用できる\n",
    "- 対象プラットフォーム（iOS、Android、HEMSなど）におけるデータ取得の業界標準を理解しており、今後の技術動向や規制についてのリスクを提⽰できる\n",
    "- 単一サーバーの物理メモリを超える複数のデータソースを組み合わせたデータ処理において、分散処理アーキテクチャやデータのインメモリ処理の特性を意識してプログラム設計ができる\n",
    "- ストリーミング処理や複合イベント処理（CEP）などを設計し、適切な⾔語やライブラリを選んでプログラム実装できる\n",
    "- RDBにおける分析関数の構文と挙動を理解し、分析関数を用いて複雑な副問合せや自己結合を解消できる\n",
    "- N：Nの結合や完全外部結合の危険性（計算量の増⼤、結果の不完全性）、暗黙の型変換の危険性（インデックス不使用、小数点以下の切り捨てなど）を考慮したSQLを記述できる\n",
    "- 記述したSQLの実⾏計画の確認と判断ができ、SQLの修正やインデックス作成により、処理時間を⼤幅に改善するようなパフォーマンスチューニングができる\n",
    "- HiveQL、Spark SQL、またはPigで使用するためのUDFが実装できる\n",
    "- なりすまし、改ざん、盗聴などのセキュリティ侵害を防御するための対策を特定できる\n",
    "- 侵⼊検知システム（IDS）やファイアウォールなどを用いて、外部からの不正アクセスを検知、防御する環境を設計できる\n",
    "- 個別の案件ごとに、依頼元との契約約款、依頼元がデータをどのように保持し利用するかに応じて、適切な匿名化の⼿法を選択し適用できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ビジネス"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 初級"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 必須\n",
    "- ビジネスにおける論理とデータの重要性を認識し、分析的でデータドリブンな考え方に基づき行動できる\n",
    "- 個人情報に関する法令の概要を理解し、守るべきポイントを説明できる\n",
    "- 報告に対する論拠不足や論理破綻を指摘された際に、相手の主張をすみやかに理解できる\n",
    "- 担当する業務領域であれば、基本的な課題の枠組みが理解できる(調達活動の5 フォースでの整理、CRM課題のRFMでの整理など)\n",
    "- 担当するタスクの遅延や障害などを発⾒した場合、迅速かつ適切に報告ができる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 選択\n",
    "- 一般的な論文構成について理解している(序論⇒アプローチ⇒検討結果⇒考察や、序論⇒本論⇒結論 など)\n",
    "- 1つの図表〜数枚程度のドキュメントを論理立ててまとめることができる(課題背景、アプローチ、検討結果、意味合い、ネクストステップ)\n",
    "- ウォーターフォール開発とアジャイル開発の違いを説明できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 中級"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 必須\n",
    "- 担当するビジネスや業界に関係する法令を理解しており、データの保持期間や運用ルールに活かすことができる\n",
    "- 様々なデータや事象を、階層やグルーピングによって、構造化できる(ピラミッド構造)\n",
    "- 既存ライブラリなどを利⽤し、解析または開発を推進する際に、知財リスクの確認など、適切な対応をとることができる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 選択\n",
    "- チーム全員がデータを取り扱う人間として相応しい倫理を持てるよう、適切にチームを管理できる\n",
    "- 個人情報の扱いに関する法令、その他のプライバシーの問題、依頼元との契約約款に基づき、匿名化すべきデータを選別できる(名寄せにより個人を特定できるもの、依頼元がデータ処理の結果をどのように保持し利用するのかなども考慮して)\n",
    "- 匿名加工情報について理解しており、適切な方法で匿名加工情報を扱うことができる\n",
    "- 初見の領域に対して、抜け漏れや重複をなくすことができる\n",
    "- 通常見受けられない現象の場合においても、分析結果の意味合いを既知の表現を組み合わせ、言語化できる\n",
    "- 10〜20枚程度のミニパッケージ(テキスト&図表)、もしくは5ページ程度の図表 込みのビジネスレポートを論理立てて作成できる\n",
    "- 自らが関連する事業領域であれば、複数の課題レイヤーにまたがっていても、KPIを 整理・構造化できる\n",
    "- 事業モデルやバリューチェーンなどの特徴や事業の主たる課題を自力で構造的に理解でき、問題の大枠を整理できる\n",
    "- 取り扱う課題領域に対して、新規課題の切り分けや枠組み化ができる\n",
    "- 財務会計と管理会計の大まかな枠組みを理解し、必要に応じて分析プロジェクト設計ができる\n",
    "- アジャイル開発体制のポイントを理解した上で、アジャイルな開発チームを立ち上げ、推進することができる\n",
    "- 類似事例の実績やPoC(Proof of Concept)を適宜利用して、プロジェクト計画に 関わるステークホルダー間の合意を形成できる\n",
    "- 自身が担当するプロジェクトやサービスを超えて、必要なデータのあたりをつけることができる\n",
    "- データの特徴を見て意味合いの明確化に向けた分析の深掘り、データ見直しの方向性を設計できる\n",
    "- 分析結果を眺め、起きている事象の背景や意味合い(真実)を見ぬくことができる\n",
    "- 適用される業務内容に応じて、モデルの総合的な評価ができる\n",
    "- 担当する案件が予算内で解決するように取り組みをデザインし、現場に実装できる\n",
    "- 事業・現場へ実装するにあたりモニタリングの仕組みを適切に組み込むことができる\n",
    "- 担当するプロジェクトで、設定された予算やツール、システム環境を適切に活⽤し、プロジェクト進⾏できる \n",
    "- 5名前後のチームを設計し、スケジュール通りに進⾏させ、ステークホルダーに対して期待値に⾒合うアウトプットを安定的に⽣み出せる\n",
    "- 担当するプロジェクトでの遅延や障害などの発⽣を検知し、リカバリーするための提案・設計ができる\n",
    "- 自⾝とチームメンバーのスキルを⼤まかに把握し、担当するプロジェクトを通してチームメンバーへのスキルアドバイスやスキル成⻑のための目標管理ができる\n",
    "- チームメンバーのスキルに応じ、研修参加や情報収集への適切なアドバイスやチーム内でのナレッジ共有を推進できる\n",
    "- データサイエンスチームの役割を認識し、担当するプロジェクトにおいて、組織内や他部門・他社間でのタスク設定や調整ができる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 上級"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 必須\n",
    "- プロフェッショナルとして、作業量ではなく、生み出す価値視点で常に判断、行動でき、依頼元にとって真に価値あるアウトプットを生み出すことをコミットできる\n",
    "- プレゼンテーションの相手からの質問や反論に対して、説得力のある形で回答できる\n",
    "- 分析結果が当初の目的を満たしていない場合に、必要に応じてプロジェクト全体を再設計できる\n",
    "- 分析的検討に基づき、経営レベルで必要なアクション、改革案を整理して結論を導くことができる\n",
    "- プロジェクトに何らかの遅延・障害などが発⽣した場合、適切なリカバリー手順の判断、リカバリー体制構築、プロジェクトオーナーに対する迅速な対応ができる\n",
    "- データサイエンスチームを自社・他社の様々な組織と関連付け、対象組織内での役割の規定、目標設定を⾏うことができる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 選択\n",
    "- データの取り扱いに関する、会社や組織全体の倫理を維持、向上させるために、必要な制度や仕組みを策定し、その運営を主導することができる\n",
    "- 未知の領域であっても、類似する事象の推測などを活用し、抜け漏れや重複をなくすことができる\n",
    "- 論理的な整理にとらわれず、批判的・複合的な視点で課題を識別できる\n",
    "- データ表現に適した言葉がない場合でも、共通認識が形成できるような言葉を新たに作り出すことができる\n",
    "- 相手や内容に応じて、自在にストーリーラインを組み上げることができる\n",
    "- 30〜50枚程度のフルパッケージ(テキスト&図表)、もしくは10ページ以上のビジ ネスレポートを論理立てて作成できる\n",
    "- 初見の事業領域であっても、KPIを構造化し、重要なKPIを見極められる\n",
    "- 領域の主要課題を他領域の課題との連関も含めて構造的に理解でき、問題の大枠を定義できる\n",
    "- 仮説や可視化された問題がなくとも、解くべき課題を構造的に整理でき、見極めるべき論点を特定できる\n",
    "- 期待される成果が達成できないケースを早期に見極め、プロジェクトの終了条件をステークホルダーと整理・合意できる\n",
    "- 他社による模倣を防ぐなど、競争力を保つ観点でアプローチの設計ができる(機械化や標準化の範囲を絞るなど)\n",
    "- プロジェクトの開始時点で、入手可能なデータ、分析手法、インフラ、ツールの生み出すビジネス価値の見積りをまとめることができる\n",
    "- 組織全体及び関連する社外のデータを見渡して、必要なデータのあたりをつけることができる\n",
    "- 分析プロセス全体を通して常時、ビジネス観点での妥当性をチェックし、データから得られた示唆が価値ある知見であるか都度判断できる\n",
    "- 担当および関連する分析プロジェクトのデータ、分析結果を顧客、外部に開示すべきか判断できる\n",
    "- データを利活用した持続性のある事業モデルを設計できる\n",
    "- 費用対効果、実行可能性、業務負荷を考慮し事業に実装ができる\n",
    "- 既存のPDCAに新たな仕込みを⾏い、次の改善的な取り組みにつなげることができる\n",
    "- 特定のビジネス課題に向けた新しいソリューションを個別の現場の特性を考慮し横展開できる \n",
    "- マルウェア、DDoS攻撃などの深刻なセキュリティ攻撃を受けた場合に対応する最新の技術を把握し、対応する専門組織（CSIRT）の構成を責任者にすみやかに提案できる\n",
    "- プロジェクトに求められるスキル要件と各メンバーのスキル・成⻑目標・性格をふまえ、現実的にトレードオフ解消とシナジーを狙ったリソースマネジメントができる\n",
    "- プロジェクトメンバーの技量を把握した上で、プロジェクト完遂に必要なツール選定、予算策定、スコープ設定、またはアウトソーシング体制を検討・構築できる\n",
    "- 複数のチームを設計し（総合的なプロジェクトマネジメント）、スケジュール通りに進⾏させ、複合的なステークホルダーに対し、期待値を超えたアウトプットを安定的に⽣み出せる\n",
    "- チームの各メンバーに対し、データサイエンティストとしてのスキル目標の設定、到達させるためのプロジェクトを通した適切なアドバイスができる\n",
    "- チーム育成の上で、データサイエンティストに求められるスキルについて、研修制度の設計やナレッジ共有の仕組み構築と運営ができる\n",
    "- チームに必要な情報やデータサイエンスの新しい技術・手法に関する情報収集戦略やラーニング⽅法を主導し、自ら情報を取捨選択し、チームにフィードバックできる\n",
    "- 依頼元やステークホルダーのビジネスをデータ⾯から理解し、分析・データ活⽤のプロジェクトを⽴ち上げ、プロジェクトにかかるコストと依頼元の利益を説明できる\n",
    "- 独自に開発する手法・アルゴリズム構築の際に、適切な専門家の助⼒を得て知財リスクの管理を⾏うことができる\n",
    "- 独自に開発した手法・アルゴリズムに対する他者からの権利侵害に備え、特許出願を含む適切な対応を⾏うことができる\n",
    "- AI・モデル開発において、事業・現場に即したガイドラインを定義できる\n",
    "-  AI・モデルの活⽤・責任範囲に関し事業・現場に即したガイドラインを定義できる\n",
    "- 学習済みモデルや⽣成されたデータの価値を理解した上で権利関係を明確にし、利⽤許諾など契約の枠組みを定義できる\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
