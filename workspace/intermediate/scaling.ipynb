{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from IPython.display import display\n",
    "pd.set_option('max_rows', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# スケーリング (scaling)\n",
    "---\n",
    "特徴量の尺度を揃えること。多くの機械学習アルゴリズム (特に kNN などの特徴空間内の距離に基づくもの) は、特徴量の尺度が揃っていないとうまく動かない。\n",
    "\n",
    "<table class=\"border\">\n",
    "    <tr>\n",
    "        <th class=\"text-center border-bottom\">正則化</th>\n",
    "        <td class=\"text-left\">係数の値の合計に基づくため、スケールの小さい (係数の大きい) 変数ほど抑制されやすい</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th class=\"text-center border-bottom\">kNN</th>\n",
    "        <td class=\"text-left\">特徴空間内の距離に基づくため、スケールの大きい変数に距離が影響されやすい</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th class=\"text-center border-bottom\">PCA</th>\n",
    "        <td class=\"text-left\">変数の共分散に基づくため、スケールの大きい変数ほど上位の成分に多く含まれやすい</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th class=\"text-center border-bottom\">SGD</th>\n",
    "        <td class=\"text-left\">パラメーター空間内の勾配に基づくため、スケールの大きい (パラメーターの勾配が急な) 変数方向に行き来を繰り返して収束が遅くなりやすい</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "トレーニングデータを変換するのに使用したのと同じパラメーターで、未知のデータも変換しないといけない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正規化 (normalization)\n",
    "---\n",
    "対象となる特徴の最小値・最大値を0・1になるように変換すること。その特徴のとる値の範囲が一定範囲内に限定される場合に有効。\n",
    "\n",
    "$\n",
    "{\\displaystyle x^{( i)} =\\frac\n",
    "    {x^{( i)} -x_{min}}\n",
    "    {x_{max} -x_{min}}\n",
    "}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 練習問題\n",
    "\n",
    "scikit-learn を用いずに`sample_n11n`データセットを正規化する。その後、正規化されたデータと最大値・最小値のパラメーターを用いて、元の値に戻す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_n11n\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0   -6.169611\n",
       "1    2.442175\n",
       "       ...   \n",
       "8    9.162787\n",
       "9    7.518653\n",
       "Name: sample_n11n, Length: 10, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(1234)\n",
    "sample_n11n = pd.Series(np.random.uniform(low=-10, high=10, size=10), name='sample_n11n')\n",
    "print('sample_n11n')\n",
    "display(sample_n11n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.000000\n",
      "1    0.561673\n",
      "       ...   \n",
      "8    1.000000\n",
      "9    0.892767\n",
      "Name: sample_n11n, Length: 10, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sample_min = sample_n11n.min()\n",
    "sample_max = sample_n11n.max()\n",
    "\n",
    "norm = (sample_n11n - sample_min) / (sample_max - sample_min)\n",
    "print(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   -6.169611\n",
      "1    2.442175\n",
      "       ...   \n",
      "8    9.162787\n",
      "9    7.518653\n",
      "Name: sample_n11n, Length: 10, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "original = norm * (sample_max - sample_min) + sample_min\n",
    "print(original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pythonでの実行方法\n",
    "---\n",
    "`sklearn.preprocessing.MinMaxScaler`を使用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MinMaxScaler??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.5616725 ],\n",
       "       [0.32116084],\n",
       "       [0.77462003],\n",
       "       [0.76759859],\n",
       "       [0.10575404],\n",
       "       [0.11080433],\n",
       "       [0.79616082],\n",
       "       [1.        ],\n",
       "       [0.8927673 ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n11n_reshape = sample_n11n.values.reshape((-1, 1))\n",
    "mm_scaler = MinMaxScaler().fit(n11n_reshape)\n",
    "# 結果の確認\n",
    "mm_scaler.transform(n11n_reshape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 標準化 (standardization)\n",
    "---\n",
    "対象となる特徴の分布が平均0・標準偏差1の正規分布となるように変換すること。多くの機械学習モデルの前処理として有効。正規化と比べて外れ値から受ける影響が少なくなる。\n",
    "\n",
    "標準化のことも正規化ということがあるので、文脈からどちらを指しているのか判断する。\n",
    "\n",
    "$\n",
    "{\\displaystyle x^{( i)} =\\frac\n",
    "    {x^{( i)} -\\mu _{x}}\n",
    "    {\\sigma _{x}}\n",
    "}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 練習問題\n",
    "\n",
    "scikit-learn を用いずに`sample_s13n`データセットを標準化する。その後、標準化されたデータと平均・標準偏差のパラメータを用いて元の値に戻す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_s13n\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    5.942870\n",
       "1    2.618049\n",
       "       ...   \n",
       "8    5.031393\n",
       "9    0.514630\n",
       "Length: 10, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(1234)\n",
    "sample_s13n = pd.Series(np.random.normal(loc=5, scale=2, size=10))\n",
    "print('sample_s13n')\n",
    "display(sample_s13n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.554762\n",
      "1   -0.944531\n",
      "       ...   \n",
      "8    0.143741\n",
      "9   -1.893045\n",
      "Length: 10, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sample_mean = sample_s13n.mean()\n",
    "sample_std = sample_s13n.std()\n",
    "\n",
    "std = (sample_s13n - sample_mean) / sample_std\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5.942870\n",
      "1    2.618049\n",
      "       ...   \n",
      "8    5.031393\n",
      "9    0.514630\n",
      "Length: 10, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "original = std * sample_std + sample_mean\n",
    "print(original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pythonでの実行方法\n",
    "---\n",
    "`sklearn.preprocessing.StandardScaler`を使用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "StandardScaler??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.58477094],\n",
       "       [-0.99562261],\n",
       "       [ 1.49861708],\n",
       "       [-0.16063212],\n",
       "       [-0.54844283],\n",
       "       [ 0.97998822],\n",
       "       [ 0.95377412],\n",
       "       [-0.46852508],\n",
       "       [ 0.15151664],\n",
       "       [-1.99544436]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s13n_reshape = sample_s13n.values.reshape((-1, 1))\n",
    "std_scaler = StandardScaler().fit(s13n_reshape)\n",
    "# 結果の確認\n",
    "std_scaler.transform(s13n_reshape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
