{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer, load_wine\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ParameterGrid, GridSearchCV, RandomizedSearchCV\n",
    "from IPython.display import display\n",
    "pd.set_option('max_rows', 5)\n",
    "pd.set_option('max_columns', 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# バリデーション"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## バリデーション (validation)\n",
    "---\n",
    "ハイパーパラメータ調整のために、学習に使用していないデータを用いてモデルを評価すること。\n",
    "\n",
    "機械学習ではモデルのパラメータはデータから自動的に学習するものとユーザーが設定するもの (クラス引数に与える値) がある。後者を特にハイパーパラメータと呼ぶ。\n",
    "\n",
    "<table class=\"border text-center\">\n",
    "    <tr class=\"background-dark\">\n",
    "        <th>種類</th>\n",
    "        <th>名称</th>\n",
    "        <th>具体例</th>\n",
    "    </tr>\n",
    "    <tr class=\"background-bright\">\n",
    "        <td>データから自動的に学習するもの</td>\n",
    "        <td>パラメータ</td>\n",
    "        <td>$w$ (ウェイト) や $b$ (バイアス)</td>\n",
    "    </tr>\n",
    "    <tr class=\"background-bright\">\n",
    "        <td>ユーザーが設定するもの</td>\n",
    "        <td>ハイパーパラメータ</td>\n",
    "        <td>L1 ・ L2正則化の $\\alpha$</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "ハイパーパラメータの値をチューニング (調整) することで精度を向上できる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## バリデーションの必要性\n",
    "---\n",
    "テストデータでの精度向上を目指してチューニングすると、ハイパーパラメータの値にテストデータの情報が盛り込まれてしまう。  \n",
    "= 手動でテストデータの情報をモデルに与え、**テストデータに対して過学習**を起こし、本当に未知のデータに対する汎化性能が測定できなくなる。\n",
    "\n",
    " 1. あるハイパーパラメータの値 $( \\theta _{1})$ を使ってトレーニングデータ $( x_{train} ,y_{train})$ で学習\n",
    " 1. テストデータ $( x_{test} ,y_{test})$ での精度 $( L_{\\theta _{1}})$ を見る\n",
    " 1. 別のハイパーパラメータの値 $( \\theta _{2} ,\\theta _{3} ,\\cdots )$ を試す\n",
    " 1. テストデータで精度がよかったハイパーパラメータ $( \\theta _{best})$ を採用\n",
    " 1. 採用したハイパーパラメータ $( \\theta _{best})$ はテストデータで精度が出るように調整されたものなので、実際に運用してみると期待した精度が出ない\n",
    "\n",
    "そこで、ハイパーパラメータのチューニングには、データセットをトレーニングデータ・バリデーションデータ・テストデータに分割し、\n",
    "\n",
    " - トレーニングデータで学習 → バリデーションデータでハイパーパラメータをチューニング → テストデータで汎化能力確認\n",
    "\n",
    "<table class=\"text-center\">\n",
    "    <tr>\n",
    "        <th colspan=\"5\">データセット</th>\n",
    "    </tr>\n",
    "    <tr class=\"border-bottom\">\n",
    "        <th>トレーニングデータ</th>\n",
    "        <th></th>\n",
    "        <th>バリデーションデータ</th>\n",
    "        <th></th>\n",
    "        <th>テストデータ</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>学習</td>\n",
    "        <td>→</td>\n",
    "        <td>ハイパーパラメータのチューニング</td>\n",
    "        <td>→</td>\n",
    "        <td>汎化性能の確認</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "という手順を踏む。\n",
    "\n",
    "バリデーションデータを使ってハイパーパラメータを決定した後は、そのハイパーパラメータとデータセット全体 (トレーニングデータ+バリデーションデータ) を使ってパラメータを学習させる。\n",
    "\n",
    " 1. あるハイパーパラメータの値 $( \\theta _{1})$ を使ってトレーニングデータ $( x_{train} ,y_{train})$ で学習\n",
    " 1. バリデーションデータ $( x_{valid} ,y_{valid})$ での精度 $( L_{\\theta _{1}})$ を見る\n",
    " 1. 別のハイパーパラメータの値 $( \\theta _{2} ,\\theta _{3} ,\\cdots )$ を試す\n",
    " 1. バリデーションデータで精度がよかったハイパーパラメータ $( \\theta _{best})$ を採用\n",
    " 1. 採用したハイパーパラメータ $( \\theta_{best})$ を使って学習用の全データ $( x_{train}+x_{valid} ,y_{train}+y_{valid})$ で学習\n",
    " 1. テストデータ $( x_{test} ,y_{test})$ で汎化性能を確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## バリデーションの種類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ホールドアウト法\n",
    "---\n",
    "テストと同様にデータセットの一部からバリデーション用のデータを取り出し、トレーニングデータで学習、バリデーションデータでハイパーパラメーターの性能を評価する方法。\n",
    "\n",
    "トレーニングデータ・バリデーションデータ・テストデータの割合は、 $6:2:2$ や $8:1:1$ などバリデーションデータとテストデータの割合を同程度にすることが多い。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pythonでのホールドアウト法の実行方法\n",
    "---\n",
    "テストデータと同様に`sklearn.model_selection.train_test_split`を使用する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交差検証法 (cross-validation)\n",
    "---\n",
    "訓練データを $k$ 個に分割し、1個をバリデーションデータ・残りを訓練データとして利用し性能評価、それを全ての組で行って、平均性能をそのハイパーパラメーターの性能とする。\n",
    "\n",
    "<table class=\"border text-center\">\n",
    "    <tr class=\"background-dark\">\n",
    "        <th colspan=\"6\">パラメータ $\\theta _{1}$ の学習</th>\n",
    "    </tr>\n",
    "    <tr class=\"background-dark\">\n",
    "        <td></td>\n",
    "        <td>データセット1</td>\n",
    "        <td>データセット2</td>\n",
    "        <td>…</td>\n",
    "        <td>データセットk</td>\n",
    "        <td>平均</td>\n",
    "    </tr>\n",
    "    <tr class=\"background-bright\">\n",
    "        <td>1回目</td>\n",
    "        <td>バリデーションデータ</td>\n",
    "        <td>トレーニングデータ</td>\n",
    "        <td>…</td>\n",
    "        <td>トレーニングデータ</td>\n",
    "        <td rowspan=\"4\">$\\theta _{1}$ の性能</td>\n",
    "    </tr>\n",
    "    <tr class=\"background-bright\">\n",
    "        <td>2回目</td>\n",
    "        <td>トレーニングデータ</td>\n",
    "        <td>バリデーションデータ</td>\n",
    "        <td>…</td>\n",
    "        <td>トレーニングデータ</td>\n",
    "    </tr>\n",
    "    <tr class=\"background-bright\">\n",
    "        <td colspan=\"5\">$\\vdots$</td>\n",
    "    </tr>\n",
    "    <tr class=\"background-bright\">\n",
    "        <td>k回目</td>\n",
    "        <td>トレーニングデータ</td>\n",
    "        <td>トレーニングデータ</td>\n",
    "        <td>…</td>\n",
    "        <td>バリデーションデータ</td>\n",
    "    </tr>\n",
    "    <tr class=\"border-none background-default\">\n",
    "        <td colspan=\"6\"></td>\n",
    "    </tr>\n",
    "    <tr class=\"background-dark\">\n",
    "        <th colspan=\"6\">パラメータ $\\theta _{2}$ の学習</th>\n",
    "    </tr>\n",
    "    <tr class=\"background-dark\">\n",
    "        <td></td>\n",
    "        <td>データセット1</td>\n",
    "        <td>データセット2</td>\n",
    "        <td>…</td>\n",
    "        <td>データセットk</td>\n",
    "        <td>平均</td>\n",
    "    </tr>\n",
    "    <tr class=\"background-bright\">\n",
    "        <td>1回目</td>\n",
    "        <td>バリデーションデータ</td>\n",
    "        <td>トレーニングデータ</td>\n",
    "        <td>…</td>\n",
    "        <td>トレーニングデータ</td>\n",
    "        <td rowspan=\"4\">$\\theta _{2}$ の性能</td>\n",
    "    </tr>\n",
    "    <tr class=\"background-bright\">\n",
    "        <td>2回目</td>\n",
    "        <td>トレーニングデータ</td>\n",
    "        <td>バリデーションデータ</td>\n",
    "        <td>…</td>\n",
    "        <td>トレーニングデータ</td>\n",
    "    </tr>\n",
    "    <tr class=\"background-bright\">\n",
    "        <td colspan=\"5\">$\\vdots$</td>\n",
    "    </tr>\n",
    "    <tr class=\"background-bright\">\n",
    "        <td>k回目</td>\n",
    "        <td>トレーニングデータ</td>\n",
    "        <td>トレーニングデータ</td>\n",
    "        <td>…</td>\n",
    "        <td>バリデーションデータ</td>\n",
    "    </tr>\n",
    "    <tr class=\"border-none background-default\">\n",
    "        <td colspan=\"6\">$\\vdots$</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    " - トレーニングデータとバリデーションデータの分け方による誤差に強い\n",
    " - 各ハイパーパラメーターごとに $k$ 回学習を行うので、実行にかかる時間が長くなる\n",
    "\n",
    "特に分類問題で完全にランダムにデータを分割すると、各グループでクラスの偏りが発生する可能性があるので、元データのクラス比率を維持しながら分割する層化 k 分割交差検証 (stratified k-fold cross-validation) を用いることも多い。\n",
    "\n",
    "極端にデータが少ない場合にはバリデーションデータとして 1 サンプルのみを使用する LOO (Leave One Out) も使われることがある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### クロスバリデーションとテスト\n",
    "---\n",
    "クロスバリデーションを実施する際もテストを行うのが望ましいが、計算コストの高いクロスバリデーションは**データが少ない場合に使われることが多く**、テストデータを十分に確保できない。また、 1 つのハイパーパラメーターに対して複数のデータ分割で評価しているので、ホールドアウト法より過学習を起こしにくい。  \n",
    "そのため、クロスバリデーションを実施する場合にはテストは行わないことも多い。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pythonでのクロスバリデーションの実行方法\n",
    "---\n",
    "`sklearn.model_selection.cross_validate`や各モデル名の後に CV のついたもの (`RidgeCV`など) を使用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hide_input": true,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wine\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>...</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  ...   hue  \\\n",
       "0      14.23        1.71  2.43               15.6  ...  1.04   \n",
       "1      13.20        1.78  2.14               11.2  ...  1.05   \n",
       "..       ...         ...   ...                ...  ...   ...   \n",
       "176    13.17        2.59  2.37               20.0  ...  0.60   \n",
       "177    14.13        4.10  2.74               24.5  ...  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  target  \n",
       "0                            3.92   1065.0     0.0  \n",
       "1                            3.40   1050.0     0.0  \n",
       "..                            ...      ...     ...  \n",
       "176                          1.62    840.0     2.0  \n",
       "177                          1.60    560.0     2.0  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loader = load_wine()\n",
    "wine = pd.DataFrame(np.column_stack([loader.data, loader.target]),\n",
    "                    columns=list(loader.feature_names) + ['target'])\n",
    "print('wine')\n",
    "display(wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function cross_validate in module sklearn.model_selection._validation:\n",
      "\n",
      "cross_validate(estimator, X, y=None, *, groups=None, scoring=None, cv=None, n_jobs=None, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score=nan)\n",
      "    Evaluate metric(s) by cross-validation and also record fit/score times.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <multimetric_cross_validation>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    estimator : estimator object implementing 'fit'\n",
      "        The object to use to fit the data.\n",
      "    \n",
      "    X : array-like of shape (n_samples, n_features)\n",
      "        The data to fit. Can be for example a list, or an array.\n",
      "    \n",
      "    y : array-like of shape (n_samples,) or (n_samples, n_outputs),             default=None\n",
      "        The target variable to try to predict in the case of\n",
      "        supervised learning.\n",
      "    \n",
      "    groups : array-like of shape (n_samples,), default=None\n",
      "        Group labels for the samples used while splitting the dataset into\n",
      "        train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      "        instance (e.g., :class:`GroupKFold`).\n",
      "    \n",
      "    scoring : str, callable, list/tuple, or dict, default=None\n",
      "        A single str (see :ref:`scoring_parameter`) or a callable\n",
      "        (see :ref:`scoring`) to evaluate the predictions on the test set.\n",
      "    \n",
      "        For evaluating multiple metrics, either give a list of (unique) strings\n",
      "        or a dict with names as keys and callables as values.\n",
      "    \n",
      "        NOTE that when using custom scorers, each scorer should return a single\n",
      "        value. Metric functions returning a list/array of values can be wrapped\n",
      "        into multiple scorers that return one value each.\n",
      "    \n",
      "        See :ref:`multimetric_grid_search` for an example.\n",
      "    \n",
      "        If None, the estimator's score method is used.\n",
      "    \n",
      "    cv : int, cross-validation generator or an iterable, default=None\n",
      "        Determines the cross-validation splitting strategy.\n",
      "        Possible inputs for cv are:\n",
      "    \n",
      "        - None, to use the default 5-fold cross validation,\n",
      "        - int, to specify the number of folds in a `(Stratified)KFold`,\n",
      "        - :term:`CV splitter`,\n",
      "        - An iterable yielding (train, test) splits as arrays of indices.\n",
      "    \n",
      "        For int/None inputs, if the estimator is a classifier and ``y`` is\n",
      "        either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      "        other cases, :class:`KFold` is used.\n",
      "    \n",
      "        Refer :ref:`User Guide <cross_validation>` for the various\n",
      "        cross-validation strategies that can be used here.\n",
      "    \n",
      "        .. versionchanged:: 0.22\n",
      "            ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      "    \n",
      "    n_jobs : int, default=None\n",
      "        The number of CPUs to use to do the computation.\n",
      "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "        for more details.\n",
      "    \n",
      "    verbose : int, default=0\n",
      "        The verbosity level.\n",
      "    \n",
      "    fit_params : dict, default=None\n",
      "        Parameters to pass to the fit method of the estimator.\n",
      "    \n",
      "    pre_dispatch : int or str, default='2*n_jobs'\n",
      "        Controls the number of jobs that get dispatched during parallel\n",
      "        execution. Reducing this number can be useful to avoid an\n",
      "        explosion of memory consumption when more jobs get dispatched\n",
      "        than CPUs can process. This parameter can be:\n",
      "    \n",
      "            - None, in which case all the jobs are immediately\n",
      "              created and spawned. Use this for lightweight and\n",
      "              fast-running jobs, to avoid delays due to on-demand\n",
      "              spawning of the jobs\n",
      "    \n",
      "            - An int, giving the exact number of total jobs that are\n",
      "              spawned\n",
      "    \n",
      "            - A str, giving an expression as a function of n_jobs,\n",
      "              as in '2*n_jobs'\n",
      "    \n",
      "    return_train_score : bool, default=False\n",
      "        Whether to include train scores.\n",
      "        Computing training scores is used to get insights on how different\n",
      "        parameter settings impact the overfitting/underfitting trade-off.\n",
      "        However computing the scores on the training set can be computationally\n",
      "        expensive and is not strictly required to select the parameters that\n",
      "        yield the best generalization performance.\n",
      "    \n",
      "        .. versionadded:: 0.19\n",
      "    \n",
      "        .. versionchanged:: 0.21\n",
      "            Default value was changed from ``True`` to ``False``\n",
      "    \n",
      "    return_estimator : bool, default=False\n",
      "        Whether to return the estimators fitted on each split.\n",
      "    \n",
      "        .. versionadded:: 0.20\n",
      "    \n",
      "    error_score : 'raise' or numeric\n",
      "        Value to assign to the score if an error occurs in estimator fitting.\n",
      "        If set to 'raise', the error is raised.\n",
      "        If a numeric value is given, FitFailedWarning is raised. This parameter\n",
      "        does not affect the refit step, which will always raise the error.\n",
      "    \n",
      "        .. versionadded:: 0.20\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    scores : dict of float arrays of shape (n_splits,)\n",
      "        Array of scores of the estimator for each run of the cross validation.\n",
      "    \n",
      "        A dict of arrays containing the score/time arrays for each scorer is\n",
      "        returned. The possible keys for this ``dict`` are:\n",
      "    \n",
      "            ``test_score``\n",
      "                The score array for test scores on each cv split.\n",
      "                Suffix ``_score`` in ``test_score`` changes to a specific\n",
      "                metric like ``test_r2`` or ``test_auc`` if there are\n",
      "                multiple scoring metrics in the scoring parameter.\n",
      "            ``train_score``\n",
      "                The score array for train scores on each cv split.\n",
      "                Suffix ``_score`` in ``train_score`` changes to a specific\n",
      "                metric like ``train_r2`` or ``train_auc`` if there are\n",
      "                multiple scoring metrics in the scoring parameter.\n",
      "                This is available only if ``return_train_score`` parameter\n",
      "                is ``True``.\n",
      "            ``fit_time``\n",
      "                The time for fitting the estimator on the train\n",
      "                set for each cv split.\n",
      "            ``score_time``\n",
      "                The time for scoring the estimator on the test set for each\n",
      "                cv split. (Note time for scoring on the train set is not\n",
      "                included even if ``return_train_score`` is set to ``True``\n",
      "            ``estimator``\n",
      "                The estimator objects for each cv split.\n",
      "                This is available only if ``return_estimator`` parameter\n",
      "                is set to ``True``.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn import datasets, linear_model\n",
      "    >>> from sklearn.model_selection import cross_validate\n",
      "    >>> from sklearn.metrics import make_scorer\n",
      "    >>> from sklearn.metrics import confusion_matrix\n",
      "    >>> from sklearn.svm import LinearSVC\n",
      "    >>> diabetes = datasets.load_diabetes()\n",
      "    >>> X = diabetes.data[:150]\n",
      "    >>> y = diabetes.target[:150]\n",
      "    >>> lasso = linear_model.Lasso()\n",
      "    \n",
      "    Single metric evaluation using ``cross_validate``\n",
      "    \n",
      "    >>> cv_results = cross_validate(lasso, X, y, cv=3)\n",
      "    >>> sorted(cv_results.keys())\n",
      "    ['fit_time', 'score_time', 'test_score']\n",
      "    >>> cv_results['test_score']\n",
      "    array([0.33150734, 0.08022311, 0.03531764])\n",
      "    \n",
      "    Multiple metric evaluation using ``cross_validate``\n",
      "    (please refer the ``scoring`` parameter doc for more information)\n",
      "    \n",
      "    >>> scores = cross_validate(lasso, X, y, cv=3,\n",
      "    ...                         scoring=('r2', 'neg_mean_squared_error'),\n",
      "    ...                         return_train_score=True)\n",
      "    >>> print(scores['test_neg_mean_squared_error'])\n",
      "    [-3635.5... -3573.3... -6114.7...]\n",
      "    >>> print(scores['train_r2'])\n",
      "    [0.28010158 0.39088426 0.22784852]\n",
      "    \n",
      "    See Also\n",
      "    ---------\n",
      "    :func:`sklearn.model_selection.cross_val_score`:\n",
      "        Run cross-validation for single metric evaluation.\n",
      "    \n",
      "    :func:`sklearn.model_selection.cross_val_predict`:\n",
      "        Get predictions from each split of cross-validation for diagnostic\n",
      "        purposes.\n",
      "    \n",
      "    :func:`sklearn.metrics.make_scorer`:\n",
      "        Make a scorer from a performance metric or loss function.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cross_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00844717, 0.09507132, 0.00844002, 0.01233053, 0.00655556]),\n",
       " 'score_time': array([0.00326467, 0.0130744 , 0.00452209, 0.00895691, 0.00270534]),\n",
       " 'test_score': array([0.94444444, 0.83333333, 0.88888889, 0.91428571, 0.82857143])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = wine.iloc[:, :-1]\n",
    "y = wine.iloc[:, -1]\n",
    "model = DecisionTreeClassifier()\n",
    "cross_validate(model, x, y, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ハイパーパラメーターサーチ\n",
    "---\n",
    "様々なハイパーパラメーターを試して、精度のいいものを探すこと。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### グリッドサーチ\n",
    "---\n",
    "与えられたハイパーパラメーターの値候補の全組み合わせを試して、最も精度のよい組み合わせを探す方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pythonでのグリッドサーチの実行方法\n",
    "---\n",
    "`sklearn.model_selection.GridSearchCV`を使用する。`sklearn.model_selection.ParameterGrid`で探索するハイパーパラメーターの全組み合わせを作成しておく必要がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class ParameterGrid in module sklearn.model_selection._search:\n",
      "\n",
      "class ParameterGrid(builtins.object)\n",
      " |  ParameterGrid(param_grid)\n",
      " |  \n",
      " |  Grid of parameters with a discrete number of values for each.\n",
      " |  \n",
      " |  Can be used to iterate over parameter value combinations with the\n",
      " |  Python built-in function iter.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <grid_search>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  param_grid : dict of str to sequence, or sequence of such\n",
      " |      The parameter grid to explore, as a dictionary mapping estimator\n",
      " |      parameters to sequences of allowed values.\n",
      " |  \n",
      " |      An empty dict signifies default parameters.\n",
      " |  \n",
      " |      A sequence of dicts signifies a sequence of grids to search, and is\n",
      " |      useful to avoid exploring parameter combinations that make no sense\n",
      " |      or have no effect. See the examples below.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.model_selection import ParameterGrid\n",
      " |  >>> param_grid = {'a': [1, 2], 'b': [True, False]}\n",
      " |  >>> list(ParameterGrid(param_grid)) == (\n",
      " |  ...    [{'a': 1, 'b': True}, {'a': 1, 'b': False},\n",
      " |  ...     {'a': 2, 'b': True}, {'a': 2, 'b': False}])\n",
      " |  True\n",
      " |  \n",
      " |  >>> grid = [{'kernel': ['linear']}, {'kernel': ['rbf'], 'gamma': [1, 10]}]\n",
      " |  >>> list(ParameterGrid(grid)) == [{'kernel': 'linear'},\n",
      " |  ...                               {'kernel': 'rbf', 'gamma': 1},\n",
      " |  ...                               {'kernel': 'rbf', 'gamma': 10}]\n",
      " |  True\n",
      " |  >>> ParameterGrid(grid)[1] == {'kernel': 'rbf', 'gamma': 1}\n",
      " |  True\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  :class:`GridSearchCV`:\n",
      " |      Uses :class:`ParameterGrid` to perform a full parallelized parameter\n",
      " |      search.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getitem__(self, ind)\n",
      " |      Get the parameters that would be ``ind``th in iteration\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ind : int\n",
      " |          The iteration index\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict of str to any\n",
      " |          Equal to list(self)[ind]\n",
      " |  \n",
      " |  __init__(self, param_grid)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Iterate over the points in the grid.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : iterator over dict of str to any\n",
      " |          Yields dictionaries mapping each estimator parameter to one of its\n",
      " |          allowed values.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Number of points on the grid.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ParameterGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'criterion': 'gini', 'max_depth': 3},\n",
       " {'criterion': 'gini', 'max_depth': 4},\n",
       " {'criterion': 'gini', 'max_depth': 5},\n",
       " {'criterion': 'entropy', 'max_depth': 3},\n",
       " {'criterion': 'entropy', 'max_depth': 4},\n",
       " {'criterion': 'entropy', 'max_depth': 5}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = dict(criterion=['gini', 'entropy'], max_depth=[3, 4, 5])\n",
    "grid = ParameterGrid(params)\n",
    "list(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GridSearchCV in module sklearn.model_selection._search:\n",
      "\n",
      "class GridSearchCV(BaseSearchCV)\n",
      " |  GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, iid='deprecated', refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
      " |  \n",
      " |  Exhaustive search over specified parameter values for an estimator.\n",
      " |  \n",
      " |  Important members are fit, predict.\n",
      " |  \n",
      " |  GridSearchCV implements a \"fit\" and a \"score\" method.\n",
      " |  It also implements \"predict\", \"predict_proba\", \"decision_function\",\n",
      " |  \"transform\" and \"inverse_transform\" if they are implemented in the\n",
      " |  estimator used.\n",
      " |  \n",
      " |  The parameters of the estimator used to apply these methods are optimized\n",
      " |  by cross-validated grid-search over a parameter grid.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <grid_search>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  estimator : estimator object.\n",
      " |      This is assumed to implement the scikit-learn estimator interface.\n",
      " |      Either estimator needs to provide a ``score`` function,\n",
      " |      or ``scoring`` must be passed.\n",
      " |  \n",
      " |  param_grid : dict or list of dictionaries\n",
      " |      Dictionary with parameters names (`str`) as keys and lists of\n",
      " |      parameter settings to try as values, or a list of such\n",
      " |      dictionaries, in which case the grids spanned by each dictionary\n",
      " |      in the list are explored. This enables searching over any sequence\n",
      " |      of parameter settings.\n",
      " |  \n",
      " |  scoring : str, callable, list/tuple or dict, default=None\n",
      " |      A single str (see :ref:`scoring_parameter`) or a callable\n",
      " |      (see :ref:`scoring`) to evaluate the predictions on the test set.\n",
      " |  \n",
      " |      For evaluating multiple metrics, either give a list of (unique) strings\n",
      " |      or a dict with names as keys and callables as values.\n",
      " |  \n",
      " |      NOTE that when using custom scorers, each scorer should return a single\n",
      " |      value. Metric functions returning a list/array of values can be wrapped\n",
      " |      into multiple scorers that return one value each.\n",
      " |  \n",
      " |      See :ref:`multimetric_grid_search` for an example.\n",
      " |  \n",
      " |      If None, the estimator's score method is used.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      Number of jobs to run in parallel.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |  \n",
      " |      .. versionchanged:: v0.20\n",
      " |         `n_jobs` default changed from 1 to None\n",
      " |  \n",
      " |  pre_dispatch : int, or str, default=n_jobs\n",
      " |      Controls the number of jobs that get dispatched during parallel\n",
      " |      execution. Reducing this number can be useful to avoid an\n",
      " |      explosion of memory consumption when more jobs get dispatched\n",
      " |      than CPUs can process. This parameter can be:\n",
      " |  \n",
      " |          - None, in which case all the jobs are immediately\n",
      " |            created and spawned. Use this for lightweight and\n",
      " |            fast-running jobs, to avoid delays due to on-demand\n",
      " |            spawning of the jobs\n",
      " |  \n",
      " |          - An int, giving the exact number of total jobs that are\n",
      " |            spawned\n",
      " |  \n",
      " |          - A str, giving an expression as a function of n_jobs,\n",
      " |            as in '2*n_jobs'\n",
      " |  \n",
      " |  iid : bool, default=False\n",
      " |      If True, return the average score across folds, weighted by the number\n",
      " |      of samples in each test set. In this case, the data is assumed to be\n",
      " |      identically distributed across the folds, and the loss minimized is\n",
      " |      the total loss per sample, and not the mean loss across the folds.\n",
      " |  \n",
      " |      .. deprecated:: 0.22\n",
      " |          Parameter ``iid`` is deprecated in 0.22 and will be removed in 0.24\n",
      " |  \n",
      " |  cv : int, cross-validation generator or an iterable, default=None\n",
      " |      Determines the cross-validation splitting strategy.\n",
      " |      Possible inputs for cv are:\n",
      " |  \n",
      " |      - None, to use the default 5-fold cross validation,\n",
      " |      - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
      " |      - :term:`CV splitter`,\n",
      " |      - An iterable yielding (train, test) splits as arrays of indices.\n",
      " |  \n",
      " |      For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
      " |      either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      " |      other cases, :class:`KFold` is used.\n",
      " |  \n",
      " |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      " |      cross-validation strategies that can be used here.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |          ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      " |  \n",
      " |  refit : bool, str, or callable, default=True\n",
      " |      Refit an estimator using the best found parameters on the whole\n",
      " |      dataset.\n",
      " |  \n",
      " |      For multiple metric evaluation, this needs to be a `str` denoting the\n",
      " |      scorer that would be used to find the best parameters for refitting\n",
      " |      the estimator at the end.\n",
      " |  \n",
      " |      Where there are considerations other than maximum score in\n",
      " |      choosing a best estimator, ``refit`` can be set to a function which\n",
      " |      returns the selected ``best_index_`` given ``cv_results_``. In that\n",
      " |      case, the ``best_estimator_`` and ``best_params_`` will be set\n",
      " |      according to the returned ``best_index_`` while the ``best_score_``\n",
      " |      attribute will not be available.\n",
      " |  \n",
      " |      The refitted estimator is made available at the ``best_estimator_``\n",
      " |      attribute and permits using ``predict`` directly on this\n",
      " |      ``GridSearchCV`` instance.\n",
      " |  \n",
      " |      Also for multiple metric evaluation, the attributes ``best_index_``,\n",
      " |      ``best_score_`` and ``best_params_`` will only be available if\n",
      " |      ``refit`` is set and all of them will be determined w.r.t this specific\n",
      " |      scorer.\n",
      " |  \n",
      " |      See ``scoring`` parameter to know more about multiple metric\n",
      " |      evaluation.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |          Support for callable added.\n",
      " |  \n",
      " |  verbose : integer\n",
      " |      Controls the verbosity: the higher, the more messages.\n",
      " |  \n",
      " |  error_score : 'raise' or numeric, default=np.nan\n",
      " |      Value to assign to the score if an error occurs in estimator fitting.\n",
      " |      If set to 'raise', the error is raised. If a numeric value is given,\n",
      " |      FitFailedWarning is raised. This parameter does not affect the refit\n",
      " |      step, which will always raise the error.\n",
      " |  \n",
      " |  return_train_score : bool, default=False\n",
      " |      If ``False``, the ``cv_results_`` attribute will not include training\n",
      " |      scores.\n",
      " |      Computing training scores is used to get insights on how different\n",
      " |      parameter settings impact the overfitting/underfitting trade-off.\n",
      " |      However computing the scores on the training set can be computationally\n",
      " |      expensive and is not strictly required to select the parameters that\n",
      " |      yield the best generalization performance.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |      .. versionchanged:: 0.21\n",
      " |          Default value was changed from ``True`` to ``False``\n",
      " |  \n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn import svm, datasets\n",
      " |  >>> from sklearn.model_selection import GridSearchCV\n",
      " |  >>> iris = datasets.load_iris()\n",
      " |  >>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      " |  >>> svc = svm.SVC()\n",
      " |  >>> clf = GridSearchCV(svc, parameters)\n",
      " |  >>> clf.fit(iris.data, iris.target)\n",
      " |  GridSearchCV(estimator=SVC(),\n",
      " |               param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})\n",
      " |  >>> sorted(clf.cv_results_.keys())\n",
      " |  ['mean_fit_time', 'mean_score_time', 'mean_test_score',...\n",
      " |   'param_C', 'param_kernel', 'params',...\n",
      " |   'rank_test_score', 'split0_test_score',...\n",
      " |   'split2_test_score', ...\n",
      " |   'std_fit_time', 'std_score_time', 'std_test_score']\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  cv_results_ : dict of numpy (masked) ndarrays\n",
      " |      A dict with keys as column headers and values as columns, that can be\n",
      " |      imported into a pandas ``DataFrame``.\n",
      " |  \n",
      " |      For instance the below given table\n",
      " |  \n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...|\n",
      " |      +============+===========+============+=================+===+=========+\n",
      " |      |  'poly'    |     --    |      2     |       0.80      |...|    2    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'poly'    |     --    |      3     |       0.70      |...|    4    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.1   |     --     |       0.80      |...|    3    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.2   |     --     |       0.93      |...|    1    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |  \n",
      " |      will be represented by a ``cv_results_`` dict of::\n",
      " |  \n",
      " |          {\n",
      " |          'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],\n",
      " |                                       mask = [False False False False]...)\n",
      " |          'param_gamma': masked_array(data = [-- -- 0.1 0.2],\n",
      " |                                      mask = [ True  True False False]...),\n",
      " |          'param_degree': masked_array(data = [2.0 3.0 -- --],\n",
      " |                                       mask = [False False  True  True]...),\n",
      " |          'split0_test_score'  : [0.80, 0.70, 0.80, 0.93],\n",
      " |          'split1_test_score'  : [0.82, 0.50, 0.70, 0.78],\n",
      " |          'mean_test_score'    : [0.81, 0.60, 0.75, 0.85],\n",
      " |          'std_test_score'     : [0.01, 0.10, 0.05, 0.08],\n",
      " |          'rank_test_score'    : [2, 4, 3, 1],\n",
      " |          'split0_train_score' : [0.80, 0.92, 0.70, 0.93],\n",
      " |          'split1_train_score' : [0.82, 0.55, 0.70, 0.87],\n",
      " |          'mean_train_score'   : [0.81, 0.74, 0.70, 0.90],\n",
      " |          'std_train_score'    : [0.01, 0.19, 0.00, 0.03],\n",
      " |          'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],\n",
      " |          'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],\n",
      " |          'mean_score_time'    : [0.01, 0.06, 0.04, 0.04],\n",
      " |          'std_score_time'     : [0.00, 0.00, 0.00, 0.01],\n",
      " |          'params'             : [{'kernel': 'poly', 'degree': 2}, ...],\n",
      " |          }\n",
      " |  \n",
      " |      NOTE\n",
      " |  \n",
      " |      The key ``'params'`` is used to store a list of parameter\n",
      " |      settings dicts for all the parameter candidates.\n",
      " |  \n",
      " |      The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
      " |      ``std_score_time`` are all in seconds.\n",
      " |  \n",
      " |      For multi-metric evaluation, the scores for all the scorers are\n",
      " |      available in the ``cv_results_`` dict at the keys ending with that\n",
      " |      scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n",
      " |      above. ('split0_test_precision', 'mean_train_precision' etc.)\n",
      " |  \n",
      " |  best_estimator_ : estimator\n",
      " |      Estimator that was chosen by the search, i.e. estimator\n",
      " |      which gave highest score (or smallest loss if specified)\n",
      " |      on the left out data. Not available if ``refit=False``.\n",
      " |  \n",
      " |      See ``refit`` parameter for more information on allowed values.\n",
      " |  \n",
      " |  best_score_ : float\n",
      " |      Mean cross-validated score of the best_estimator\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |      This attribute is not available if ``refit`` is a function.\n",
      " |  \n",
      " |  best_params_ : dict\n",
      " |      Parameter setting that gave the best results on the hold out data.\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  best_index_ : int\n",
      " |      The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
      " |      candidate parameter setting.\n",
      " |  \n",
      " |      The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
      " |      the parameter setting for the best model, that gives the highest\n",
      " |      mean score (``search.best_score_``).\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  scorer_ : function or a dict\n",
      " |      Scorer function used on the held out data to choose the best\n",
      " |      parameters for the model.\n",
      " |  \n",
      " |      For multi-metric evaluation, this attribute holds the validated\n",
      " |      ``scoring`` dict which maps the scorer key to the scorer callable.\n",
      " |  \n",
      " |  n_splits_ : int\n",
      " |      The number of cross-validation splits (folds/iterations).\n",
      " |  \n",
      " |  refit_time_ : float\n",
      " |      Seconds used for refitting the best model on the whole dataset.\n",
      " |  \n",
      " |      This is present only if ``refit`` is not False.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The parameters selected are those that maximize the score of the left out\n",
      " |  data, unless an explicit score is passed in which case it is used instead.\n",
      " |  \n",
      " |  If `n_jobs` was set to a value higher than one, the data is copied for each\n",
      " |  point in the grid (and not `n_jobs` times). This is done for efficiency\n",
      " |  reasons if individual jobs take very little time, but may raise errors if\n",
      " |  the dataset is large and not enough memory is available.  A workaround in\n",
      " |  this case is to set `pre_dispatch`. Then, the memory is copied only\n",
      " |  `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
      " |  n_jobs`.\n",
      " |  \n",
      " |  See Also\n",
      " |  ---------\n",
      " |  :class:`ParameterGrid`:\n",
      " |      generates all the combinations of a hyperparameter grid.\n",
      " |  \n",
      " |  :func:`sklearn.model_selection.train_test_split`:\n",
      " |      utility function to split the data into a development set usable\n",
      " |      for fitting a GridSearchCV instance and an evaluation set for\n",
      " |      its final evaluation.\n",
      " |  \n",
      " |  :func:`sklearn.metrics.make_scorer`:\n",
      " |      Make a scorer from a performance metric or loss function.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GridSearchCV\n",
      " |      BaseSearchCV\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, estimator, param_grid, *, scoring=None, n_jobs=None, iid='deprecated', refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseSearchCV:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Call decision_function on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``decision_function``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  fit(self, X, y=None, *, groups=None, **fit_params)\n",
      " |      Run fit with all sets of parameters.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Training vector, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      groups : array-like of shape (n_samples,), default=None\n",
      " |          Group labels for the samples used while splitting the dataset into\n",
      " |          train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      " |          instance (e.g., :class:`~sklearn.model_selection.GroupKFold`).\n",
      " |      \n",
      " |      **fit_params : dict of str -> object\n",
      " |          Parameters passed to the ``fit`` method of the estimator\n",
      " |  \n",
      " |  inverse_transform(self, Xt)\n",
      " |      Call inverse_transform on the estimator with the best found params.\n",
      " |      \n",
      " |      Only available if the underlying estimator implements\n",
      " |      ``inverse_transform`` and ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      Xt : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Call predict on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Call predict_log_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_log_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Call predict_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  score(self, X, y=None)\n",
      " |      Returns the score on the given data, if the estimator has been refit.\n",
      " |      \n",
      " |      This uses the score defined by ``scoring`` where provided, and the\n",
      " |      ``best_estimator_.score`` method otherwise.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input data, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Call transform on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if the underlying estimator supports ``transform`` and\n",
      " |      ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseSearchCV:\n",
      " |  \n",
      " |  classes_\n",
      " |  \n",
      " |  n_features_in_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.MetaEstimatorMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.0364994 , 0.01473827, 0.0245657 , 0.01613584, 0.0151865 ,\n",
       "        0.01307125]),\n",
       " 'std_fit_time': array([0.01408598, 0.0059776 , 0.01026655, 0.0088567 , 0.00873395,\n",
       "        0.00330426]),\n",
       " 'mean_score_time': array([0.01353846, 0.01218252, 0.01154552, 0.00857816, 0.00781469,\n",
       "        0.00542741]),\n",
       " 'std_score_time': array([0.00682476, 0.01307534, 0.0058919 , 0.00519834, 0.00255785,\n",
       "        0.000248  ]),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'entropy', 'entropy',\n",
       "                    'entropy'],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[3, 4, 5, 3, 4, 5],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'gini', 'max_depth': 3},\n",
       "  {'criterion': 'gini', 'max_depth': 4},\n",
       "  {'criterion': 'gini', 'max_depth': 5},\n",
       "  {'criterion': 'entropy', 'max_depth': 3},\n",
       "  {'criterion': 'entropy', 'max_depth': 4},\n",
       "  {'criterion': 'entropy', 'max_depth': 5}],\n",
       " 'split0_test_score': array([0.94444444, 0.91666667, 0.88888889, 0.91666667, 0.91666667,\n",
       "        0.91666667]),\n",
       " 'split1_test_score': array([0.86111111, 0.86111111, 0.80555556, 0.88888889, 0.77777778,\n",
       "        0.77777778]),\n",
       " 'split2_test_score': array([0.86111111, 0.94444444, 0.91666667, 0.94444444, 0.91666667,\n",
       "        0.91666667]),\n",
       " 'split3_test_score': array([0.8       , 0.91428571, 0.91428571, 0.97142857, 0.97142857,\n",
       "        0.97142857]),\n",
       " 'split4_test_score': array([0.97142857, 0.97142857, 0.85714286, 0.88571429, 0.88571429,\n",
       "        0.88571429]),\n",
       " 'mean_test_score': array([0.88761905, 0.9215873 , 0.87650794, 0.92142857, 0.89365079,\n",
       "        0.89365079]),\n",
       " 'std_test_score': array([0.06218617, 0.0367192 , 0.04147871, 0.032823  , 0.06418471,\n",
       "        0.06418471]),\n",
       " 'rank_test_score': array([5, 1, 6, 2, 3, 3], dtype=int32)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(model, params, n_jobs=-1, cv=5)\n",
    "gs.fit(x, y)\n",
    "gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 4}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ランダムサーチ\n",
    "---\n",
    "与えられたハイパーパラメーターの値候補からランダムに組み合わせて、精度のよい組み合わせを探す方法。  \n",
    "複数のハイパーパラメーターのうち、精度に大きく影響するものは少数であったり、どのハイパーパラメーターをどのくらいの範囲で探索するのが効率的かわからなかったりするので、グリッドサーチを実施する前に絞り込みに利用したりする。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pythonでのランダムサーチの実行方法\n",
    "---\n",
    "`sklearn.model_selection.RandomizedSearchCV`を使用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class RandomizedSearchCV in module sklearn.model_selection._search:\n",
      "\n",
      "class RandomizedSearchCV(BaseSearchCV)\n",
      " |  RandomizedSearchCV(estimator, param_distributions, *, n_iter=10, scoring=None, n_jobs=None, iid='deprecated', refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', random_state=None, error_score=nan, return_train_score=False)\n",
      " |  \n",
      " |  Randomized search on hyper parameters.\n",
      " |  \n",
      " |  RandomizedSearchCV implements a \"fit\" and a \"score\" method.\n",
      " |  It also implements \"predict\", \"predict_proba\", \"decision_function\",\n",
      " |  \"transform\" and \"inverse_transform\" if they are implemented in the\n",
      " |  estimator used.\n",
      " |  \n",
      " |  The parameters of the estimator used to apply these methods are optimized\n",
      " |  by cross-validated search over parameter settings.\n",
      " |  \n",
      " |  In contrast to GridSearchCV, not all parameter values are tried out, but\n",
      " |  rather a fixed number of parameter settings is sampled from the specified\n",
      " |  distributions. The number of parameter settings that are tried is\n",
      " |  given by n_iter.\n",
      " |  \n",
      " |  If all parameters are presented as a list,\n",
      " |  sampling without replacement is performed. If at least one parameter\n",
      " |  is given as a distribution, sampling with replacement is used.\n",
      " |  It is highly recommended to use continuous distributions for continuous\n",
      " |  parameters.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <randomized_parameter_search>`.\n",
      " |  \n",
      " |  .. versionadded:: 0.14\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  estimator : estimator object.\n",
      " |      A object of that type is instantiated for each grid point.\n",
      " |      This is assumed to implement the scikit-learn estimator interface.\n",
      " |      Either estimator needs to provide a ``score`` function,\n",
      " |      or ``scoring`` must be passed.\n",
      " |  \n",
      " |  param_distributions : dict or list of dicts\n",
      " |      Dictionary with parameters names (`str`) as keys and distributions\n",
      " |      or lists of parameters to try. Distributions must provide a ``rvs``\n",
      " |      method for sampling (such as those from scipy.stats.distributions).\n",
      " |      If a list is given, it is sampled uniformly.\n",
      " |      If a list of dicts is given, first a dict is sampled uniformly, and\n",
      " |      then a parameter is sampled using that dict as above.\n",
      " |  \n",
      " |  n_iter : int, default=10\n",
      " |      Number of parameter settings that are sampled. n_iter trades\n",
      " |      off runtime vs quality of the solution.\n",
      " |  \n",
      " |  scoring : str, callable, list/tuple or dict, default=None\n",
      " |      A single str (see :ref:`scoring_parameter`) or a callable\n",
      " |      (see :ref:`scoring`) to evaluate the predictions on the test set.\n",
      " |  \n",
      " |      For evaluating multiple metrics, either give a list of (unique) strings\n",
      " |      or a dict with names as keys and callables as values.\n",
      " |  \n",
      " |      NOTE that when using custom scorers, each scorer should return a single\n",
      " |      value. Metric functions returning a list/array of values can be wrapped\n",
      " |      into multiple scorers that return one value each.\n",
      " |  \n",
      " |      See :ref:`multimetric_grid_search` for an example.\n",
      " |  \n",
      " |      If None, the estimator's score method is used.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      Number of jobs to run in parallel.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |  \n",
      " |      .. versionchanged:: v0.20\n",
      " |         `n_jobs` default changed from 1 to None\n",
      " |  \n",
      " |  pre_dispatch : int, or str, default=None\n",
      " |      Controls the number of jobs that get dispatched during parallel\n",
      " |      execution. Reducing this number can be useful to avoid an\n",
      " |      explosion of memory consumption when more jobs get dispatched\n",
      " |      than CPUs can process. This parameter can be:\n",
      " |  \n",
      " |          - None, in which case all the jobs are immediately\n",
      " |            created and spawned. Use this for lightweight and\n",
      " |            fast-running jobs, to avoid delays due to on-demand\n",
      " |            spawning of the jobs\n",
      " |  \n",
      " |          - An int, giving the exact number of total jobs that are\n",
      " |            spawned\n",
      " |  \n",
      " |          - A str, giving an expression as a function of n_jobs,\n",
      " |            as in '2*n_jobs'\n",
      " |  \n",
      " |  iid : bool, default=False\n",
      " |      If True, return the average score across folds, weighted by the number\n",
      " |      of samples in each test set. In this case, the data is assumed to be\n",
      " |      identically distributed across the folds, and the loss minimized is\n",
      " |      the total loss per sample, and not the mean loss across the folds.\n",
      " |  \n",
      " |      .. deprecated:: 0.22\n",
      " |          Parameter ``iid`` is deprecated in 0.22 and will be removed in 0.24\n",
      " |  \n",
      " |  cv : int, cross-validation generator or an iterable, default=None\n",
      " |      Determines the cross-validation splitting strategy.\n",
      " |      Possible inputs for cv are:\n",
      " |  \n",
      " |      - None, to use the default 5-fold cross validation,\n",
      " |      - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
      " |      - :term:`CV splitter`,\n",
      " |      - An iterable yielding (train, test) splits as arrays of indices.\n",
      " |  \n",
      " |      For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
      " |      either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      " |      other cases, :class:`KFold` is used.\n",
      " |  \n",
      " |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      " |      cross-validation strategies that can be used here.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |          ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      " |  \n",
      " |  refit : bool, str, or callable, default=True\n",
      " |      Refit an estimator using the best found parameters on the whole\n",
      " |      dataset.\n",
      " |  \n",
      " |      For multiple metric evaluation, this needs to be a `str` denoting the\n",
      " |      scorer that would be used to find the best parameters for refitting\n",
      " |      the estimator at the end.\n",
      " |  \n",
      " |      Where there are considerations other than maximum score in\n",
      " |      choosing a best estimator, ``refit`` can be set to a function which\n",
      " |      returns the selected ``best_index_`` given the ``cv_results``. In that\n",
      " |      case, the ``best_estimator_`` and ``best_params_`` will be set\n",
      " |      according to the returned ``best_index_`` while the ``best_score_``\n",
      " |      attribute will not be available.\n",
      " |  \n",
      " |      The refitted estimator is made available at the ``best_estimator_``\n",
      " |      attribute and permits using ``predict`` directly on this\n",
      " |      ``RandomizedSearchCV`` instance.\n",
      " |  \n",
      " |      Also for multiple metric evaluation, the attributes ``best_index_``,\n",
      " |      ``best_score_`` and ``best_params_`` will only be available if\n",
      " |      ``refit`` is set and all of them will be determined w.r.t this specific\n",
      " |      scorer.\n",
      " |  \n",
      " |      See ``scoring`` parameter to know more about multiple metric\n",
      " |      evaluation.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |          Support for callable added.\n",
      " |  \n",
      " |  verbose : integer\n",
      " |      Controls the verbosity: the higher, the more messages.\n",
      " |  \n",
      " |  random_state : int or RandomState instance, default=None\n",
      " |      Pseudo random number generator state used for random uniform sampling\n",
      " |      from lists of possible values instead of scipy.stats distributions.\n",
      " |      Pass an int for reproducible output across multiple\n",
      " |      function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  error_score : 'raise' or numeric, default=np.nan\n",
      " |      Value to assign to the score if an error occurs in estimator fitting.\n",
      " |      If set to 'raise', the error is raised. If a numeric value is given,\n",
      " |      FitFailedWarning is raised. This parameter does not affect the refit\n",
      " |      step, which will always raise the error.\n",
      " |  \n",
      " |  return_train_score : bool, default=False\n",
      " |      If ``False``, the ``cv_results_`` attribute will not include training\n",
      " |      scores.\n",
      " |      Computing training scores is used to get insights on how different\n",
      " |      parameter settings impact the overfitting/underfitting trade-off.\n",
      " |      However computing the scores on the training set can be computationally\n",
      " |      expensive and is not strictly required to select the parameters that\n",
      " |      yield the best generalization performance.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |      .. versionchanged:: 0.21\n",
      " |          Default value was changed from ``True`` to ``False``\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  cv_results_ : dict of numpy (masked) ndarrays\n",
      " |      A dict with keys as column headers and values as columns, that can be\n",
      " |      imported into a pandas ``DataFrame``.\n",
      " |  \n",
      " |      For instance the below given table\n",
      " |  \n",
      " |      +--------------+-------------+-------------------+---+---------------+\n",
      " |      | param_kernel | param_gamma | split0_test_score |...|rank_test_score|\n",
      " |      +==============+=============+===================+===+===============+\n",
      " |      |    'rbf'     |     0.1     |       0.80        |...|       2       |\n",
      " |      +--------------+-------------+-------------------+---+---------------+\n",
      " |      |    'rbf'     |     0.2     |       0.90        |...|       1       |\n",
      " |      +--------------+-------------+-------------------+---+---------------+\n",
      " |      |    'rbf'     |     0.3     |       0.70        |...|       1       |\n",
      " |      +--------------+-------------+-------------------+---+---------------+\n",
      " |  \n",
      " |      will be represented by a ``cv_results_`` dict of::\n",
      " |  \n",
      " |          {\n",
      " |          'param_kernel' : masked_array(data = ['rbf', 'rbf', 'rbf'],\n",
      " |                                        mask = False),\n",
      " |          'param_gamma'  : masked_array(data = [0.1 0.2 0.3], mask = False),\n",
      " |          'split0_test_score'  : [0.80, 0.90, 0.70],\n",
      " |          'split1_test_score'  : [0.82, 0.50, 0.70],\n",
      " |          'mean_test_score'    : [0.81, 0.70, 0.70],\n",
      " |          'std_test_score'     : [0.01, 0.20, 0.00],\n",
      " |          'rank_test_score'    : [3, 1, 1],\n",
      " |          'split0_train_score' : [0.80, 0.92, 0.70],\n",
      " |          'split1_train_score' : [0.82, 0.55, 0.70],\n",
      " |          'mean_train_score'   : [0.81, 0.74, 0.70],\n",
      " |          'std_train_score'    : [0.01, 0.19, 0.00],\n",
      " |          'mean_fit_time'      : [0.73, 0.63, 0.43],\n",
      " |          'std_fit_time'       : [0.01, 0.02, 0.01],\n",
      " |          'mean_score_time'    : [0.01, 0.06, 0.04],\n",
      " |          'std_score_time'     : [0.00, 0.00, 0.00],\n",
      " |          'params'             : [{'kernel' : 'rbf', 'gamma' : 0.1}, ...],\n",
      " |          }\n",
      " |  \n",
      " |      NOTE\n",
      " |  \n",
      " |      The key ``'params'`` is used to store a list of parameter\n",
      " |      settings dicts for all the parameter candidates.\n",
      " |  \n",
      " |      The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
      " |      ``std_score_time`` are all in seconds.\n",
      " |  \n",
      " |      For multi-metric evaluation, the scores for all the scorers are\n",
      " |      available in the ``cv_results_`` dict at the keys ending with that\n",
      " |      scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n",
      " |      above. ('split0_test_precision', 'mean_train_precision' etc.)\n",
      " |  \n",
      " |  best_estimator_ : estimator\n",
      " |      Estimator that was chosen by the search, i.e. estimator\n",
      " |      which gave highest score (or smallest loss if specified)\n",
      " |      on the left out data. Not available if ``refit=False``.\n",
      " |  \n",
      " |      For multi-metric evaluation, this attribute is present only if\n",
      " |      ``refit`` is specified.\n",
      " |  \n",
      " |      See ``refit`` parameter for more information on allowed values.\n",
      " |  \n",
      " |  best_score_ : float\n",
      " |      Mean cross-validated score of the best_estimator.\n",
      " |  \n",
      " |      For multi-metric evaluation, this is not available if ``refit`` is\n",
      " |      ``False``. See ``refit`` parameter for more information.\n",
      " |  \n",
      " |      This attribute is not available if ``refit`` is a function.\n",
      " |  \n",
      " |  best_params_ : dict\n",
      " |      Parameter setting that gave the best results on the hold out data.\n",
      " |  \n",
      " |      For multi-metric evaluation, this is not available if ``refit`` is\n",
      " |      ``False``. See ``refit`` parameter for more information.\n",
      " |  \n",
      " |  best_index_ : int\n",
      " |      The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
      " |      candidate parameter setting.\n",
      " |  \n",
      " |      The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
      " |      the parameter setting for the best model, that gives the highest\n",
      " |      mean score (``search.best_score_``).\n",
      " |  \n",
      " |      For multi-metric evaluation, this is not available if ``refit`` is\n",
      " |      ``False``. See ``refit`` parameter for more information.\n",
      " |  \n",
      " |  scorer_ : function or a dict\n",
      " |      Scorer function used on the held out data to choose the best\n",
      " |      parameters for the model.\n",
      " |  \n",
      " |      For multi-metric evaluation, this attribute holds the validated\n",
      " |      ``scoring`` dict which maps the scorer key to the scorer callable.\n",
      " |  \n",
      " |  n_splits_ : int\n",
      " |      The number of cross-validation splits (folds/iterations).\n",
      " |  \n",
      " |  refit_time_ : float\n",
      " |      Seconds used for refitting the best model on the whole dataset.\n",
      " |  \n",
      " |      This is present only if ``refit`` is not False.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The parameters selected are those that maximize the score of the held-out\n",
      " |  data, according to the scoring parameter.\n",
      " |  \n",
      " |  If `n_jobs` was set to a value higher than one, the data is copied for each\n",
      " |  parameter setting(and not `n_jobs` times). This is done for efficiency\n",
      " |  reasons if individual jobs take very little time, but may raise errors if\n",
      " |  the dataset is large and not enough memory is available.  A workaround in\n",
      " |  this case is to set `pre_dispatch`. Then, the memory is copied only\n",
      " |  `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
      " |  n_jobs`.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  :class:`GridSearchCV`:\n",
      " |      Does exhaustive search over a grid of parameters.\n",
      " |  \n",
      " |  :class:`ParameterSampler`:\n",
      " |      A generator over parameter settings, constructed from\n",
      " |      param_distributions.\n",
      " |  \n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.datasets import load_iris\n",
      " |  >>> from sklearn.linear_model import LogisticRegression\n",
      " |  >>> from sklearn.model_selection import RandomizedSearchCV\n",
      " |  >>> from scipy.stats import uniform\n",
      " |  >>> iris = load_iris()\n",
      " |  >>> logistic = LogisticRegression(solver='saga', tol=1e-2, max_iter=200,\n",
      " |  ...                               random_state=0)\n",
      " |  >>> distributions = dict(C=uniform(loc=0, scale=4),\n",
      " |  ...                      penalty=['l2', 'l1'])\n",
      " |  >>> clf = RandomizedSearchCV(logistic, distributions, random_state=0)\n",
      " |  >>> search = clf.fit(iris.data, iris.target)\n",
      " |  >>> search.best_params_\n",
      " |  {'C': 2..., 'penalty': 'l1'}\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      RandomizedSearchCV\n",
      " |      BaseSearchCV\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, estimator, param_distributions, *, n_iter=10, scoring=None, n_jobs=None, iid='deprecated', refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', random_state=None, error_score=nan, return_train_score=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseSearchCV:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Call decision_function on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``decision_function``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  fit(self, X, y=None, *, groups=None, **fit_params)\n",
      " |      Run fit with all sets of parameters.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Training vector, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      groups : array-like of shape (n_samples,), default=None\n",
      " |          Group labels for the samples used while splitting the dataset into\n",
      " |          train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      " |          instance (e.g., :class:`~sklearn.model_selection.GroupKFold`).\n",
      " |      \n",
      " |      **fit_params : dict of str -> object\n",
      " |          Parameters passed to the ``fit`` method of the estimator\n",
      " |  \n",
      " |  inverse_transform(self, Xt)\n",
      " |      Call inverse_transform on the estimator with the best found params.\n",
      " |      \n",
      " |      Only available if the underlying estimator implements\n",
      " |      ``inverse_transform`` and ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      Xt : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Call predict on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Call predict_log_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_log_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Call predict_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  score(self, X, y=None)\n",
      " |      Returns the score on the given data, if the estimator has been refit.\n",
      " |      \n",
      " |      This uses the score defined by ``scoring`` where provided, and the\n",
      " |      ``best_estimator_.score`` method otherwise.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input data, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Call transform on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if the underlying estimator supports ``transform`` and\n",
      " |      ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseSearchCV:\n",
      " |  \n",
      " |  classes_\n",
      " |  \n",
      " |  n_features_in_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.MetaEstimatorMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(RandomizedSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.01502481, 0.02238603, 0.00731196]),\n",
       " 'std_fit_time': array([0.01079678, 0.01055039, 0.00118628]),\n",
       " 'mean_score_time': array([0.00596137, 0.00772924, 0.00674858]),\n",
       " 'std_score_time': array([0.00326713, 0.00433882, 0.00370852]),\n",
       " 'param_max_depth': masked_array(data=[5, 4, 5],\n",
       "              mask=[False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'entropy'],\n",
       "              mask=[False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 5, 'criterion': 'gini'},\n",
       "  {'max_depth': 4, 'criterion': 'gini'},\n",
       "  {'max_depth': 5, 'criterion': 'entropy'}],\n",
       " 'split0_test_score': array([0.88888889, 0.91666667, 0.91666667]),\n",
       " 'split1_test_score': array([0.77777778, 0.77777778, 0.83333333]),\n",
       " 'split2_test_score': array([0.88888889, 0.94444444, 0.94444444]),\n",
       " 'split3_test_score': array([0.91428571, 0.91428571, 0.97142857]),\n",
       " 'split4_test_score': array([0.85714286, 0.97142857, 0.88571429]),\n",
       " 'mean_test_score': array([0.86539683, 0.90492063, 0.91031746]),\n",
       " 'std_test_score': array([0.04741119, 0.06689756, 0.04789865]),\n",
       " 'rank_test_score': array([3, 2, 1], dtype=int32)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = RandomizedSearchCV(model,\n",
    "                        params,\n",
    "                        n_iter=3,\n",
    "                        n_jobs=-1,\n",
    "                        cv=5,\n",
    "                        random_state=1234)\n",
    "rs.fit(x, y)\n",
    "rs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'criterion': 'entropy'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推薦図書\n",
    "---\n",
    "- [Python 機械学習プログラミング 達人データサイエンティストによる理論と実践](https://www.amazon.co.jp/Python-%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0-%E9%81%94%E4%BA%BA%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%83%86%E3%82%A3%E3%82%B9%E3%83%88%E3%81%AB%E3%82%88%E3%82%8B%E7%90%86%E8%AB%96%E3%81%A8%E5%AE%9F%E8%B7%B5-impress-gear/dp/4295003379/)\n",
    "- [Kaggleで勝つデータ分析の技術](https://www.amazon.co.jp/Kaggle%E3%81%A7%E5%8B%9D%E3%81%A4%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%81%AE%E6%8A%80%E8%A1%93-%E9%96%80%E8%84%87-%E5%A4%A7%E8%BC%94/dp/4297108437/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
