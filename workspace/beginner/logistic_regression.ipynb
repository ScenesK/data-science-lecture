{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('max_rows', 5)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ロジスティック回帰\n",
    "---\n",
    "2 値変数 ( 2 種類の値をとる) を目的変数として、対応するカテゴリにそのデータが属する確率を推定する手法の 1 つ。\n",
    "\n",
    "<table class=\"border text-center background-bright\">\n",
    "    <tr class=\"background-dark\">\n",
    "        <th></th>\n",
    "        <th>$x$</th>\n",
    "        <th>正解</th>\n",
    "        <th class=\"border-right-double\">$y$</th>\n",
    "        <th>$\\hat{y}$</th>\n",
    "        <th>Aである確率</th>\n",
    "        <th>Bである確率</th>\n",
    "        <th>予測</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>1</td>\n",
    "        <td class=\"text-right\">1.1</td>\n",
    "        <td>A</td>\n",
    "        <td class=\"border-right-double\">1</td>\n",
    "        <td>0.98</td>\n",
    "        <td class=\"text-right\">98%</td>\n",
    "        <td class=\"text-right\">2%</td>\n",
    "        <td>A</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>2</td>\n",
    "        <td class=\"text-right\">0.5</td>\n",
    "        <td>B</td>\n",
    "        <td class=\"border-right-double\">0</td>\n",
    "        <td>0.55</td>\n",
    "        <td class=\"text-right\">55%</td>\n",
    "        <td class=\"text-right\">45%</td>\n",
    "        <td>A</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td colspan=\"8\">$\\vdots$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>n</td>\n",
    "        <td class=\"text-right\">-2.5</td>\n",
    "        <td>B</td>\n",
    "        <td class=\"border-right-double\">0</td>\n",
    "        <td>0.04</td>\n",
    "        <td class=\"text-right\">4%</td>\n",
    "        <td class=\"text-right\">96%</td>\n",
    "        <td>B</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ダミー変数\n",
    "---\n",
    "カテゴリ変数 (主に名義尺度) を 0 または 1 の値をとる 2 値変数に変換して数値計算可能にする手法。  \n",
    "One-hot エンコーディングとも呼ぶ。\n",
    "\n",
    "<table class=\"background-bright border text-center\">\n",
    "    <tr>\n",
    "        <th class=\"background-default border-top-none border-left-none border-bottom\" rowspan=\"2\"></th>\n",
    "        <th class=\"background-dark\">カテゴリ変数</th>\n",
    "        <td class=\"background-default border-top-none border-bottom-none\" rowspan=\"2\"></td>\n",
    "        <th class=\"background-dark\" colspan=\"3\">ダミー変数</th>\n",
    "    </tr>\n",
    "    <tr class=\"background-dark border-bottom\">\n",
    "        <th>色</th>\n",
    "        <th>赤</th>\n",
    "        <th>緑</th>\n",
    "        <th>青</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>1</td>\n",
    "        <td>赤</td>\n",
    "        <td class=\"background-default border-top-none border-bottom-none\" rowspan=\"3\">→</td>\n",
    "        <td>1</td>\n",
    "        <td>0</td>\n",
    "        <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>2</td>\n",
    "        <td>緑</td>\n",
    "        <td>0</td>\n",
    "        <td>1</td>\n",
    "        <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>3</td>\n",
    "        <td>青</td>\n",
    "        <td>0</td>\n",
    "        <td>0</td>\n",
    "        <td>1</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "ダミー変数は 1 列削っても情報は失われない (その他の変数から削除された列の値がわかる) ので、特にカテゴリの水準 (カテゴリ数) が 2 つしかない場合には 1 列だけで表現することが多い。\n",
    "\n",
    "<table class=\"background-bright border text-center\">\n",
    "    <tr>\n",
    "        <th class=\"background-default border-top-none border-left-none border-bottom\" rowspan=\"2\"></th>\n",
    "        <th class=\"background-dark\">カテゴリ変数</th>\n",
    "        <th class=\"background-default border-top-none border-bottom-none\" rowspan=\"2\"></th>\n",
    "        <th class=\"background-dark\" colspan=\"2\">ダミー変数</th>\n",
    "    </tr>\n",
    "    <tr class=\"background-dark border-bottom\">\n",
    "        <th>性別</th>\n",
    "        <th>男</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>1</td>\n",
    "        <td>男</td>\n",
    "        <td class=\"background-default border-top-none border-bottom-none\" rowspan=\"2\">→</td>\n",
    "        <td>1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>2</td>\n",
    "        <td>女</td>\n",
    "        <td>0</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "ダミー変数を用いずに各カテゴリに $1,\\ 2,\\ 3,\\ \\cdots $ のような数値を割り振ると、カテゴリ間に順序が生じてしまうので行ってはいけない。  \n",
    "例えば、名義尺度の変数に赤 = 1 ・緑 = 2 ・青 = 3 のように割り振ると、赤 < 緑 < 青という順序尺度の変数になってしまう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 確率の推定方法\n",
    "---\n",
    "回帰分析を利用すると、データから実数値 $(-\\infty \\sim \\infty)$ を推定できるので、実数値→確率 $(0\\sim 1)$ に変換できると便利。そこで、累積分布関数を使って実数を確率に変換することが考えられる。  \n",
    "その分布 (累積分布関数) にロジスティック分布 (ロジスティック関数) を使うのがロジスティック回帰。\n",
    "\n",
    "$\\displaystyle ロジスティック関数\\ f( x) =\\frac{e^{x}}{1+e^{x}} =\\frac{1}{1+e^{-x}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "練習問題\n",
    "\n",
    "---\n",
    "ロジスティック分布の累積分布関数のグラフを表示する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "解答例\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "solution2": "hidden"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-6, 6, 100)\n",
    "y = 1 / (1 + np.exp(-x))\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ロジスティック分布は正規分布に似ているが、正規分布より計算しやすいのが特徴。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "練習問題\n",
    "\n",
    "---\n",
    "ロジスティック分布の確率密度関数のグラフを表示する。確率密度関数 $f'( x)$ は累積分布関数を $f( x)$ とすると、以下で表される。\n",
    "\n",
    "$\\displaystyle f'( x) =f( x) \\times ( 1-f( x))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "解答例\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "solution2": "hidden"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-6, 6, 100)\n",
    "f = lambda x: 1 / (1 + np.exp(-x))\n",
    "plt.plot(x, f(x) * (1 - f(x)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pythonでのロジスティック回帰の実行\n",
    "---\n",
    "`sklearn.linear_model.LogisticRegression`を用いる。 scikit-learn の実装は厳密には上の説明と異なるが、引数`C` $\\rightarrow \\infty $ または`penalty='none'`で両者は一致する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hide_input": true,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.158174</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.460149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-1.377130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-0.998298</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x  y\n",
       "0  -0.158174  0\n",
       "1  -2.460149  0\n",
       "..       ... ..\n",
       "98 -1.377130  0\n",
       "99 -0.998298  0\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = make_classification(n_features=1,\n",
    "                           n_informative=1,\n",
    "                           n_redundant=0,\n",
    "                           n_clusters_per_class=1,\n",
    "                           random_state=1234)\n",
    "clf = pd.DataFrame(dict(x=x.ravel(), y=y))\n",
    "print('clf')\n",
    "display(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LogisticRegression in module sklearn.linear_model._logistic:\n",
      "\n",
      "class LogisticRegression(sklearn.base.BaseEstimator, sklearn.linear_model._base.LinearClassifierMixin, sklearn.linear_model._base.SparseCoefMixin)\n",
      " |  LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
      " |  \n",
      " |  Logistic Regression (aka logit, MaxEnt) classifier.\n",
      " |  \n",
      " |  In the multiclass case, the training algorithm uses the one-vs-rest (OvR)\n",
      " |  scheme if the 'multi_class' option is set to 'ovr', and uses the\n",
      " |  cross-entropy loss if the 'multi_class' option is set to 'multinomial'.\n",
      " |  (Currently the 'multinomial' option is supported only by the 'lbfgs',\n",
      " |  'sag', 'saga' and 'newton-cg' solvers.)\n",
      " |  \n",
      " |  This class implements regularized logistic regression using the\n",
      " |  'liblinear' library, 'newton-cg', 'sag', 'saga' and 'lbfgs' solvers. **Note\n",
      " |  that regularization is applied by default**. It can handle both dense\n",
      " |  and sparse input. Use C-ordered arrays or CSR matrices containing 64-bit\n",
      " |  floats for optimal performance; any other input format will be converted\n",
      " |  (and copied).\n",
      " |  \n",
      " |  The 'newton-cg', 'sag', and 'lbfgs' solvers support only L2 regularization\n",
      " |  with primal formulation, or no regularization. The 'liblinear' solver\n",
      " |  supports both L1 and L2 regularization, with a dual formulation only for\n",
      " |  the L2 penalty. The Elastic-Net regularization is only supported by the\n",
      " |  'saga' solver.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <logistic_regression>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  penalty : {'l1', 'l2', 'elasticnet', 'none'}, default='l2'\n",
      " |      Used to specify the norm used in the penalization. The 'newton-cg',\n",
      " |      'sag' and 'lbfgs' solvers support only l2 penalties. 'elasticnet' is\n",
      " |      only supported by the 'saga' solver. If 'none' (not supported by the\n",
      " |      liblinear solver), no regularization is applied.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |         l1 penalty with SAGA solver (allowing 'multinomial' + L1)\n",
      " |  \n",
      " |  dual : bool, default=False\n",
      " |      Dual or primal formulation. Dual formulation is only implemented for\n",
      " |      l2 penalty with liblinear solver. Prefer dual=False when\n",
      " |      n_samples > n_features.\n",
      " |  \n",
      " |  tol : float, default=1e-4\n",
      " |      Tolerance for stopping criteria.\n",
      " |  \n",
      " |  C : float, default=1.0\n",
      " |      Inverse of regularization strength; must be a positive float.\n",
      " |      Like in support vector machines, smaller values specify stronger\n",
      " |      regularization.\n",
      " |  \n",
      " |  fit_intercept : bool, default=True\n",
      " |      Specifies if a constant (a.k.a. bias or intercept) should be\n",
      " |      added to the decision function.\n",
      " |  \n",
      " |  intercept_scaling : float, default=1\n",
      " |      Useful only when the solver 'liblinear' is used\n",
      " |      and self.fit_intercept is set to True. In this case, x becomes\n",
      " |      [x, self.intercept_scaling],\n",
      " |      i.e. a \"synthetic\" feature with constant value equal to\n",
      " |      intercept_scaling is appended to the instance vector.\n",
      " |      The intercept becomes ``intercept_scaling * synthetic_feature_weight``.\n",
      " |  \n",
      " |      Note! the synthetic feature weight is subject to l1/l2 regularization\n",
      " |      as all other features.\n",
      " |      To lessen the effect of regularization on synthetic feature weight\n",
      " |      (and therefore on the intercept) intercept_scaling has to be increased.\n",
      " |  \n",
      " |  class_weight : dict or 'balanced', default=None\n",
      " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      " |      If not given, all classes are supposed to have weight one.\n",
      " |  \n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``.\n",
      " |  \n",
      " |      Note that these weights will be multiplied with sample_weight (passed\n",
      " |      through the fit method) if sample_weight is specified.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *class_weight='balanced'*\n",
      " |  \n",
      " |  random_state : int, RandomState instance, default=None\n",
      " |      Used when ``solver`` == 'sag', 'saga' or 'liblinear' to shuffle the\n",
      " |      data. See :term:`Glossary <random_state>` for details.\n",
      " |  \n",
      " |  solver : {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'},             default='lbfgs'\n",
      " |  \n",
      " |      Algorithm to use in the optimization problem.\n",
      " |  \n",
      " |      - For small datasets, 'liblinear' is a good choice, whereas 'sag' and\n",
      " |        'saga' are faster for large ones.\n",
      " |      - For multiclass problems, only 'newton-cg', 'sag', 'saga' and 'lbfgs'\n",
      " |        handle multinomial loss; 'liblinear' is limited to one-versus-rest\n",
      " |        schemes.\n",
      " |      - 'newton-cg', 'lbfgs', 'sag' and 'saga' handle L2 or no penalty\n",
      " |      - 'liblinear' and 'saga' also handle L1 penalty\n",
      " |      - 'saga' also supports 'elasticnet' penalty\n",
      " |      - 'liblinear' does not support setting ``penalty='none'``\n",
      " |  \n",
      " |      Note that 'sag' and 'saga' fast convergence is only guaranteed on\n",
      " |      features with approximately the same scale. You can\n",
      " |      preprocess the data with a scaler from sklearn.preprocessing.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         Stochastic Average Gradient descent solver.\n",
      " |      .. versionadded:: 0.19\n",
      " |         SAGA solver.\n",
      " |      .. versionchanged:: 0.22\n",
      " |          The default solver changed from 'liblinear' to 'lbfgs' in 0.22.\n",
      " |  \n",
      " |  max_iter : int, default=100\n",
      " |      Maximum number of iterations taken for the solvers to converge.\n",
      " |  \n",
      " |  multi_class : {'auto', 'ovr', 'multinomial'}, default='auto'\n",
      " |      If the option chosen is 'ovr', then a binary problem is fit for each\n",
      " |      label. For 'multinomial' the loss minimised is the multinomial loss fit\n",
      " |      across the entire probability distribution, *even when the data is\n",
      " |      binary*. 'multinomial' is unavailable when solver='liblinear'.\n",
      " |      'auto' selects 'ovr' if the data is binary, or if solver='liblinear',\n",
      " |      and otherwise selects 'multinomial'.\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |         Stochastic Average Gradient descent solver for 'multinomial' case.\n",
      " |      .. versionchanged:: 0.22\n",
      " |          Default changed from 'ovr' to 'auto' in 0.22.\n",
      " |  \n",
      " |  verbose : int, default=0\n",
      " |      For the liblinear and lbfgs solvers set verbose to any positive\n",
      " |      number for verbosity.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to True, reuse the solution of the previous call to fit as\n",
      " |      initialization, otherwise, just erase the previous solution.\n",
      " |      Useless for liblinear solver. See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      Number of CPU cores used when parallelizing over classes if\n",
      " |      multi_class='ovr'\". This parameter is ignored when the ``solver`` is\n",
      " |      set to 'liblinear' regardless of whether 'multi_class' is specified or\n",
      " |      not. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
      " |      context. ``-1`` means using all processors.\n",
      " |      See :term:`Glossary <n_jobs>` for more details.\n",
      " |  \n",
      " |  l1_ratio : float, default=None\n",
      " |      The Elastic-Net mixing parameter, with ``0 <= l1_ratio <= 1``. Only\n",
      " |      used if ``penalty='elasticnet'``. Setting ``l1_ratio=0`` is equivalent\n",
      " |      to using ``penalty='l2'``, while setting ``l1_ratio=1`` is equivalent\n",
      " |      to using ``penalty='l1'``. For ``0 < l1_ratio <1``, the penalty is a\n",
      " |      combination of L1 and L2.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes, )\n",
      " |      A list of class labels known to the classifier.\n",
      " |  \n",
      " |  coef_ : ndarray of shape (1, n_features) or (n_classes, n_features)\n",
      " |      Coefficient of the features in the decision function.\n",
      " |  \n",
      " |      `coef_` is of shape (1, n_features) when the given problem is binary.\n",
      " |      In particular, when `multi_class='multinomial'`, `coef_` corresponds\n",
      " |      to outcome 1 (True) and `-coef_` corresponds to outcome 0 (False).\n",
      " |  \n",
      " |  intercept_ : ndarray of shape (1,) or (n_classes,)\n",
      " |      Intercept (a.k.a. bias) added to the decision function.\n",
      " |  \n",
      " |      If `fit_intercept` is set to False, the intercept is set to zero.\n",
      " |      `intercept_` is of shape (1,) when the given problem is binary.\n",
      " |      In particular, when `multi_class='multinomial'`, `intercept_`\n",
      " |      corresponds to outcome 1 (True) and `-intercept_` corresponds to\n",
      " |      outcome 0 (False).\n",
      " |  \n",
      " |  n_iter_ : ndarray of shape (n_classes,) or (1, )\n",
      " |      Actual number of iterations for all classes. If binary or multinomial,\n",
      " |      it returns only 1 element. For liblinear solver, only the maximum\n",
      " |      number of iteration across all classes is given.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |  \n",
      " |          In SciPy <= 1.0.0 the number of lbfgs iterations may exceed\n",
      " |          ``max_iter``. ``n_iter_`` will now report at most ``max_iter``.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  SGDClassifier : Incrementally trained logistic regression (when given\n",
      " |      the parameter ``loss=\"log\"``).\n",
      " |  LogisticRegressionCV : Logistic regression with built-in cross validation.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The underlying C implementation uses a random number generator to\n",
      " |  select features when fitting the model. It is thus not uncommon,\n",
      " |  to have slightly different results for the same input data. If\n",
      " |  that happens, try with a smaller tol parameter.\n",
      " |  \n",
      " |  Predict output may not match that of standalone liblinear in certain\n",
      " |  cases. See :ref:`differences from liblinear <liblinear_differences>`\n",
      " |  in the narrative documentation.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  L-BFGS-B -- Software for Large-scale Bound-constrained Optimization\n",
      " |      Ciyou Zhu, Richard Byrd, Jorge Nocedal and Jose Luis Morales.\n",
      " |      http://users.iems.northwestern.edu/~nocedal/lbfgsb.html\n",
      " |  \n",
      " |  LIBLINEAR -- A Library for Large Linear Classification\n",
      " |      https://www.csie.ntu.edu.tw/~cjlin/liblinear/\n",
      " |  \n",
      " |  SAG -- Mark Schmidt, Nicolas Le Roux, and Francis Bach\n",
      " |      Minimizing Finite Sums with the Stochastic Average Gradient\n",
      " |      https://hal.inria.fr/hal-00860051/document\n",
      " |  \n",
      " |  SAGA -- Defazio, A., Bach F. & Lacoste-Julien S. (2014).\n",
      " |      SAGA: A Fast Incremental Gradient Method With Support\n",
      " |      for Non-Strongly Convex Composite Objectives\n",
      " |      https://arxiv.org/abs/1407.0202\n",
      " |  \n",
      " |  Hsiang-Fu Yu, Fang-Lan Huang, Chih-Jen Lin (2011). Dual coordinate descent\n",
      " |      methods for logistic regression and maximum entropy models.\n",
      " |      Machine Learning 85(1-2):41-75.\n",
      " |      https://www.csie.ntu.edu.tw/~cjlin/papers/maxent_dual.pdf\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.datasets import load_iris\n",
      " |  >>> from sklearn.linear_model import LogisticRegression\n",
      " |  >>> X, y = load_iris(return_X_y=True)\n",
      " |  >>> clf = LogisticRegression(random_state=0).fit(X, y)\n",
      " |  >>> clf.predict(X[:2, :])\n",
      " |  array([0, 0])\n",
      " |  >>> clf.predict_proba(X[:2, :])\n",
      " |  array([[9.8...e-01, 1.8...e-02, 1.4...e-08],\n",
      " |         [9.7...e-01, 2.8...e-02, ...e-08]])\n",
      " |  >>> clf.score(X, y)\n",
      " |  0.97...\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LogisticRegression\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.linear_model._base.LinearClassifierMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.linear_model._base.SparseCoefMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Training vector, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target vector relative to X.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,) default=None\n",
      " |          Array of weights that are assigned to individual samples.\n",
      " |          If not provided, then each sample is given unit weight.\n",
      " |      \n",
      " |          .. versionadded:: 0.17\n",
      " |             *sample_weight* support to LogisticRegression.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |          Fitted estimator.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The SAGA solver supports both float64 and float32 bit arrays.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Predict logarithm of probability estimates.\n",
      " |      \n",
      " |      The returned estimates for all classes are ordered by the\n",
      " |      label of classes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Vector to be scored, where `n_samples` is the number of samples and\n",
      " |          `n_features` is the number of features.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like of shape (n_samples, n_classes)\n",
      " |          Returns the log-probability of the sample for each class in the\n",
      " |          model, where classes are ordered as they are in ``self.classes_``.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Probability estimates.\n",
      " |      \n",
      " |      The returned estimates for all classes are ordered by the\n",
      " |      label of classes.\n",
      " |      \n",
      " |      For a multi_class problem, if multi_class is set to be \"multinomial\"\n",
      " |      the softmax function is used to find the predicted probability of\n",
      " |      each class.\n",
      " |      Else use a one-vs-rest approach, i.e calculate the probability\n",
      " |      of each class assuming it to be positive using the logistic function.\n",
      " |      and normalize these values across all the classes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Vector to be scored, where `n_samples` is the number of samples and\n",
      " |          `n_features` is the number of features.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like of shape (n_samples, n_classes)\n",
      " |          Returns the probability of the sample for each class in the model,\n",
      " |          where classes are ordered as they are in ``self.classes_``.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model._base.LinearClassifierMixin:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Predict confidence scores for samples.\n",
      " |      \n",
      " |      The confidence score for a sample is the signed distance of that\n",
      " |      sample to the hyperplane.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)\n",
      " |          Confidence scores per (sample, class) combination. In the binary\n",
      " |          case, confidence score for self.classes_[1] where >0 means this\n",
      " |          class would be predicted.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class labels for samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape [n_samples]\n",
      " |          Predicted class label per sample.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model._base.SparseCoefMixin:\n",
      " |  \n",
      " |  densify(self)\n",
      " |      Convert coefficient matrix to dense array format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member (back) to a numpy.ndarray. This is the\n",
      " |      default format of ``coef_`` and is required for fitting, so calling\n",
      " |      this method is only required on models that have previously been\n",
      " |      sparsified; otherwise, it is a no-op.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |          Fitted estimator.\n",
      " |  \n",
      " |  sparsify(self)\n",
      " |      Convert coefficient matrix to sparse format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member to a scipy.sparse matrix, which for\n",
      " |      L1-regularized models can be much more memory- and storage-efficient\n",
      " |      than the usual numpy.ndarray representation.\n",
      " |      \n",
      " |      The ``intercept_`` member is not converted.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |          Fitted estimator.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For non-sparse models, i.e. when there are not many zeros in ``coef_``,\n",
      " |      this may actually *increase* memory usage, so use this method with\n",
      " |      care. A rule of thumb is that the number of zero elements, which can\n",
      " |      be computed with ``(coef_ == 0).sum()``, must be more than 50% for this\n",
      " |      to provide significant benefits.\n",
      " |      \n",
      " |      After calling this method, further fitting with the partial_fit\n",
      " |      method (if any) will not work until you call densify.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "予測結果\n",
      "[[6.80826448e-01 3.19173552e-01]\n",
      " [9.99276492e-01 7.23508072e-04]\n",
      " [9.29576032e-02 9.07042397e-01]\n",
      " [2.41281211e-02 9.75871879e-01]\n",
      " [9.89678083e-01 1.03219170e-02]\n",
      " [9.72951037e-01 2.70489632e-02]\n",
      " [8.18492711e-02 9.18150729e-01]\n",
      " [8.28677148e-02 9.17132285e-01]\n",
      " [7.27575544e-02 9.27242446e-01]\n",
      " [4.28093735e-02 9.57190626e-01]\n",
      " [9.94245826e-01 5.75417412e-03]\n",
      " [9.99595947e-01 4.04052619e-04]\n",
      " [3.08385282e-02 9.69161472e-01]\n",
      " [1.94138713e-01 8.05861287e-01]\n",
      " [9.36296781e-01 6.37032189e-02]\n",
      " [1.39429704e-01 8.60570296e-01]\n",
      " [5.65848345e-02 9.43415165e-01]\n",
      " [9.71764567e-01 2.82354332e-02]\n",
      " [7.70810248e-03 9.92291898e-01]\n",
      " [9.01016652e-01 9.89833485e-02]\n",
      " [9.13904284e-01 8.60957159e-02]\n",
      " [1.60480825e-02 9.83951917e-01]\n",
      " [6.03531011e-02 9.39646899e-01]\n",
      " [7.91296233e-03 9.92087038e-01]\n",
      " [2.13268662e-01 7.86731338e-01]\n",
      " [9.90117437e-01 9.88256305e-03]\n",
      " [9.50385358e-01 4.96146417e-02]\n",
      " [9.56449203e-01 4.35507969e-02]\n",
      " [9.99543819e-01 4.56180904e-04]\n",
      " [7.07502363e-01 2.92497637e-01]\n",
      " [9.79760612e-01 2.02393883e-02]\n",
      " [5.71739500e-01 4.28260500e-01]\n",
      " [1.09219295e-01 8.90780705e-01]\n",
      " [5.34785975e-01 4.65214025e-01]\n",
      " [4.08439042e-02 9.59156096e-01]\n",
      " [6.75207435e-01 3.24792565e-01]\n",
      " [9.97029342e-01 2.97065800e-03]\n",
      " [4.58313089e-02 9.54168691e-01]\n",
      " [9.99723363e-01 2.76637234e-04]\n",
      " [5.36475860e-01 4.63524140e-01]\n",
      " [8.66940240e-01 1.33059760e-01]\n",
      " [6.28561759e-01 3.71438241e-01]\n",
      " [7.88598801e-02 9.21140120e-01]\n",
      " [9.87928429e-01 1.20715709e-02]\n",
      " [5.16425929e-02 9.48357407e-01]\n",
      " [7.63694204e-01 2.36305796e-01]\n",
      " [7.65373794e-01 2.34626206e-01]\n",
      " [5.93674569e-02 9.40632543e-01]\n",
      " [8.45578629e-02 9.15442137e-01]\n",
      " [9.78777925e-01 2.12220750e-02]\n",
      " [2.95090249e-01 7.04909751e-01]\n",
      " [7.72564706e-01 2.27435294e-01]\n",
      " [1.69820371e-01 8.30179629e-01]\n",
      " [5.43259661e-02 9.45674034e-01]\n",
      " [9.67725057e-01 3.22749432e-02]\n",
      " [4.71855809e-01 5.28144191e-01]\n",
      " [1.34600308e-02 9.86539969e-01]\n",
      " [6.43762078e-02 9.35623792e-01]\n",
      " [3.49874041e-02 9.65012596e-01]\n",
      " [8.04988890e-01 1.95011110e-01]\n",
      " [4.57129741e-02 9.54287026e-01]\n",
      " [9.54483661e-01 4.55163387e-02]\n",
      " [1.19241812e-01 8.80758188e-01]\n",
      " [9.28563946e-01 7.14360539e-02]\n",
      " [8.37515321e-01 1.62484679e-01]\n",
      " [9.98668724e-01 1.33127554e-03]\n",
      " [8.85707921e-02 9.11429208e-01]\n",
      " [6.96598987e-02 9.30340101e-01]\n",
      " [9.33288040e-01 6.67119596e-02]\n",
      " [1.15614968e-01 8.84385032e-01]\n",
      " [6.81631358e-01 3.18368642e-01]\n",
      " [7.25230634e-01 2.74769366e-01]\n",
      " [9.47460222e-02 9.05253978e-01]\n",
      " [1.34423378e-01 8.65576622e-01]\n",
      " [7.54000030e-01 2.45999970e-01]\n",
      " [9.44953462e-01 5.50465383e-02]\n",
      " [3.79339839e-02 9.62066016e-01]\n",
      " [9.91448591e-01 8.55140897e-03]\n",
      " [3.25939671e-02 9.67406033e-01]\n",
      " [3.05790860e-01 6.94209140e-01]\n",
      " [2.55016946e-02 9.74498305e-01]\n",
      " [9.56204500e-01 4.37955001e-02]\n",
      " [2.03006693e-01 7.96993307e-01]\n",
      " [8.31770864e-01 1.68229136e-01]\n",
      " [9.82428711e-01 1.75712886e-02]\n",
      " [1.74012385e-02 9.82598762e-01]\n",
      " [9.79248820e-01 2.07511805e-02]\n",
      " [2.36490835e-01 7.63509165e-01]\n",
      " [8.86901441e-01 1.13098559e-01]\n",
      " [9.22120432e-01 7.78795679e-02]\n",
      " [9.68746801e-01 3.12531987e-02]\n",
      " [2.38600368e-01 7.61399632e-01]\n",
      " [4.25824391e-02 9.57417561e-01]\n",
      " [1.29584759e-01 8.70415241e-01]\n",
      " [3.00021615e-02 9.69997838e-01]\n",
      " [3.49680992e-02 9.65031901e-01]\n",
      " [2.21395616e-01 7.78604384e-01]\n",
      " [6.35487530e-02 9.36451247e-01]\n",
      " [9.85009726e-01 1.49902735e-02]\n",
      " [9.57709486e-01 4.22905139e-02]]\n",
      "クラス1の確率\n",
      "[3.19173552e-01 7.23508072e-04 9.07042397e-01 9.75871879e-01\n",
      " 1.03219170e-02 2.70489632e-02 9.18150729e-01 9.17132285e-01\n",
      " 9.27242446e-01 9.57190626e-01 5.75417412e-03 4.04052619e-04\n",
      " 9.69161472e-01 8.05861287e-01 6.37032189e-02 8.60570296e-01\n",
      " 9.43415165e-01 2.82354332e-02 9.92291898e-01 9.89833485e-02\n",
      " 8.60957159e-02 9.83951917e-01 9.39646899e-01 9.92087038e-01\n",
      " 7.86731338e-01 9.88256305e-03 4.96146417e-02 4.35507969e-02\n",
      " 4.56180904e-04 2.92497637e-01 2.02393883e-02 4.28260500e-01\n",
      " 8.90780705e-01 4.65214025e-01 9.59156096e-01 3.24792565e-01\n",
      " 2.97065800e-03 9.54168691e-01 2.76637234e-04 4.63524140e-01\n",
      " 1.33059760e-01 3.71438241e-01 9.21140120e-01 1.20715709e-02\n",
      " 9.48357407e-01 2.36305796e-01 2.34626206e-01 9.40632543e-01\n",
      " 9.15442137e-01 2.12220750e-02 7.04909751e-01 2.27435294e-01\n",
      " 8.30179629e-01 9.45674034e-01 3.22749432e-02 5.28144191e-01\n",
      " 9.86539969e-01 9.35623792e-01 9.65012596e-01 1.95011110e-01\n",
      " 9.54287026e-01 4.55163387e-02 8.80758188e-01 7.14360539e-02\n",
      " 1.62484679e-01 1.33127554e-03 9.11429208e-01 9.30340101e-01\n",
      " 6.67119596e-02 8.84385032e-01 3.18368642e-01 2.74769366e-01\n",
      " 9.05253978e-01 8.65576622e-01 2.45999970e-01 5.50465383e-02\n",
      " 9.62066016e-01 8.55140897e-03 9.67406033e-01 6.94209140e-01\n",
      " 9.74498305e-01 4.37955001e-02 7.96993307e-01 1.68229136e-01\n",
      " 1.75712886e-02 9.82598762e-01 2.07511805e-02 7.63509165e-01\n",
      " 1.13098559e-01 7.78795679e-02 3.12531987e-02 7.61399632e-01\n",
      " 9.57417561e-01 8.70415241e-01 9.69997838e-01 9.65031901e-01\n",
      " 7.78604384e-01 9.36451247e-01 1.49902735e-02 4.22905139e-02]\n"
     ]
    }
   ],
   "source": [
    "# 最初にインスタンスを作成\n",
    "model = LogisticRegression()\n",
    "# fitメソッドで分布関数を求める\n",
    "# xはサイズが(サンプルサイズ × 変数の数)の行列でなければならない\n",
    "x = clf['x'].values.reshape((-1, 1))\n",
    "y = clf['y']\n",
    "model.fit(x, y)\n",
    "# 予測した確率はpredict_probaで得られる\n",
    "# 予測結果は[クラス0の確率, クラス1の確率]の配列\n",
    "print('予測結果')\n",
    "print(model.predict_proba(x))\n",
    "# クラス1の確率のみ得るには列を取り出す\n",
    "print('クラス1の確率')\n",
    "print(model.predict_proba(x)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "練習問題\n",
    "\n",
    "---\n",
    "clfデータセットの散布図とclfデータセットから学習したロジスティック回帰の予測曲線 (累積分布関数) を表示する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "解答例\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "solution2": "hidden"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = clf['x'].values.reshape((-1, 1))\n",
    "y = clf['y']\n",
    "model = LogisticRegression()\n",
    "model.fit(x, y)\n",
    "xx = np.linspace(x.min(), x.max(), 100).reshape((-1, 1))\n",
    "plt.scatter(x, y)\n",
    "plt.plot(xx, model.predict_proba(xx)[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推薦図書\n",
    "---\n",
    "- [見て試してわかる機械学習アルゴリズムの仕組み 機械学習図鑑](https://www.amazon.co.jp/%E8%A6%8B%E3%81%A6%E8%A9%A6%E3%81%97%E3%81%A6%E3%82%8F%E3%81%8B%E3%82%8B%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0%E3%81%AE%E4%BB%95%E7%B5%84%E3%81%BF-%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E5%9B%B3%E9%91%91-%E7%A7%8B%E5%BA%AD-%E4%BC%B8%E4%B9%9F-ebook/dp/B07KPSJKH8/)\n",
    "- [Python機械学習プログラミング 達人データサイエンティストによる理論と実践](https://www.amazon.co.jp/Python-%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0-%E9%81%94%E4%BA%BA%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%83%86%E3%82%A3%E3%82%B9%E3%83%88%E3%81%AB%E3%82%88%E3%82%8B%E7%90%86%E8%AB%96%E3%81%A8%E5%AE%9F%E8%B7%B5-impress-gear/dp/4295003379/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
